{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install xgboost lightgbm catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\Personal\\project_temp\\ReliSource\\1st_phase\\ReliSource\n"
     ]
    }
   ],
   "source": [
    "cd ../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UID</th>\n",
       "      <th>col_4</th>\n",
       "      <th>y</th>\n",
       "      <th>col_0_numerical</th>\n",
       "      <th>col_1_numerical</th>\n",
       "      <th>col_2_numerical</th>\n",
       "      <th>col_3_numerical</th>\n",
       "      <th>col_5_numerical</th>\n",
       "      <th>col_6_numerical</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>237000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>86193</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>169200</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>58000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>235000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2623</th>\n",
       "      <td>2623</td>\n",
       "      <td>0</td>\n",
       "      <td>102100</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2624</th>\n",
       "      <td>2624</td>\n",
       "      <td>0</td>\n",
       "      <td>129300</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2625</th>\n",
       "      <td>2625</td>\n",
       "      <td>100</td>\n",
       "      <td>275300</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2626</th>\n",
       "      <td>2626</td>\n",
       "      <td>100</td>\n",
       "      <td>150000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2627</th>\n",
       "      <td>2627</td>\n",
       "      <td>100</td>\n",
       "      <td>191475</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2628 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       UID  col_4       y  col_0_numerical  col_1_numerical  col_2_numerical  \\\n",
       "0        0    100  237000                0                0                2   \n",
       "1        1    100   86193                1                0               11   \n",
       "2        2      0  169200                0                0               18   \n",
       "3        3    100   58000                2                0               11   \n",
       "4        4      0  235000                0                0               67   \n",
       "...    ...    ...     ...              ...              ...              ...   \n",
       "2623  2623      0  102100                1                0                2   \n",
       "2624  2624      0  129300                0                0                8   \n",
       "2625  2625    100  275300                0                0                7   \n",
       "2626  2626    100  150000                0                0               11   \n",
       "2627  2627    100  191475                0                0                2   \n",
       "\n",
       "      col_3_numerical  col_5_numerical  col_6_numerical  \n",
       "0                   1                1                2  \n",
       "1                   4                4                2  \n",
       "2                   0                0                2  \n",
       "3                   1                1                2  \n",
       "4                   1                1                2  \n",
       "...               ...              ...              ...  \n",
       "2623                1                1                2  \n",
       "2624                1                1                2  \n",
       "2625                1                1                2  \n",
       "2626                1                1                2  \n",
       "2627                1                1                2  \n",
       "\n",
       "[2628 rows x 9 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_data =  pd.read_csv('data/cleaned_train_iffat.csv')\n",
    "test_data =  pd.read_csv('data/test.csv')\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.metrics import mean_squared_error\n",
    "# from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "# from sklearn.tree import DecisionTreeRegressor\n",
    "# from sklearn.ensemble import (\n",
    "#     RandomForestRegressor,\n",
    "#     GradientBoostingRegressor,\n",
    "#     AdaBoostRegressor,\n",
    "# )\n",
    "# import xgboost as xgb\n",
    "# import lightgbm as lgb\n",
    "# import catboost as catb\n",
    "# from sklearn.svm import SVR\n",
    "# from sklearn.linear_model import ElasticNet\n",
    "# from sklearn.neighbors import KNeighborsRegressor\n",
    "# from sklearn.linear_model import BayesianRidge\n",
    "# import random\n",
    "# from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "# import logging\n",
    "# import datetime  # Import the datetime module\n",
    "\n",
    "# # Generate a timestamp\n",
    "# timestamp = datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "\n",
    "# # Configure logging with the timestamp in the log filename\n",
    "# log_filename = f'logs/model_selection_{timestamp}.log'  # Include the timestamp in the filename\n",
    "\n",
    "# logging.basicConfig(filename=log_filename, level=logging.INFO, format='%(asctime)s - %(levelname)s: %(message)s')\n",
    "\n",
    "# # Function to log messages to both the console and the log file\n",
    "# def log_message(message):\n",
    "#     print(message)  # Print to console\n",
    "#     logging.info(message)  # Log to file\n",
    "\n",
    "# # The rest of your code remains the same...\n",
    "\n",
    "\n",
    "# # Split the data into training, validation, and test sets\n",
    "# for seed_number in range(100):\n",
    "#     log_message(f\"\\n====================== result for random seed: {seed_number} ======================\")\n",
    "#     X_train, X_val, y_train, y_val = train_test_split(train_data.drop(columns=[\"y\",\"UID\",\"col_4\"]), train_data[\"y\"], test_size=0.1, random_state=seed_number)\n",
    "\n",
    "#     # Define a list of regression models to compare\n",
    "#     # Define a list of regression models to compare, including previous models\n",
    "#     models = {\n",
    "#         'Linear Regression': LinearRegression(),\n",
    "#         'Ridge Regression': Ridge(),\n",
    "#         'Lasso Regression': Lasso(),\n",
    "#         'Decision Tree Regressor': DecisionTreeRegressor(),\n",
    "#         'Random Forest Regressor': RandomForestRegressor(),\n",
    "#         'Gradient Boosting Regressor': GradientBoostingRegressor(),\n",
    "#         'AdaBoost Regressor': AdaBoostRegressor(),\n",
    "#         'XGBoost Regressor': xgb.XGBRegressor(),\n",
    "#         'LightGBM Regressor': lgb.LGBMRegressor(verbose=-1),\n",
    "#         'CatBoost Regressor': catb.CatBoostRegressor(silent=True),\n",
    "#         'ElasticNet Regression': ElasticNet(),\n",
    "#         'K-Nearest Neighbors': KNeighborsRegressor(),\n",
    "#         'Support Vector Regressor': SVR(),\n",
    "#         'Bayesian Ridge Regression': BayesianRidge(),\n",
    "#     }\n",
    "\n",
    "#     # Define hyperparameter grids for each model, including previous models\n",
    "#     param_grids = {\n",
    "#         'Linear Regression': {},\n",
    "#         'Ridge Regression': {'alpha': [0.1, 1.0, 10.0]},\n",
    "#         'Lasso Regression': {'alpha': [0.1, 1.0, 10.0]},\n",
    "#         'Decision Tree Regressor': {'max_depth': [None, 10, 20, 30]},\n",
    "#         'Random Forest Regressor': {'n_estimators': [50, 100, 200], 'max_depth': [None, 10, 20, 30]},\n",
    "#         'Gradient Boosting Regressor': {'n_estimators': [50, 100, 200], 'max_depth': [3, 4, 5]},\n",
    "#         'AdaBoost Regressor': {'n_estimators': [50, 100, 200], 'learning_rate': [0.01, 0.1, 1.0]},\n",
    "#         'XGBoost Regressor': {'n_estimators': [50, 100, 200], 'max_depth': [3, 4, 5]},\n",
    "#         'LightGBM Regressor': {'n_estimators': [50, 100, 200], 'max_depth': [3, 4, 5]},\n",
    "#         'CatBoost Regressor': {'iterations': [50, 100, 200], 'depth': [4, 6, 8]},\n",
    "#         'ElasticNet Regression': {'alpha': [0.1, 1.0, 10.0], 'l1_ratio': [0.25, 0.5, 0.75]},\n",
    "#         'K-Nearest Neighbors': {'n_neighbors': [3, 5, 7, 10], 'weights': ['uniform', 'distance']},\n",
    "#         'Support Vector Regressor': {'C': [0.1, 1.0, 10.0], 'kernel': ['linear', 'rbf']},\n",
    "#         'Bayesian Ridge Regression': {'max_iter': [100, 300, 500], 'alpha_1': [1e-6, 1e-7], 'alpha_2': [1e-6, 1e-7]},\n",
    "#     }\n",
    "\n",
    "\n",
    "#     # Initialize variables to store best models, their RMSE scores, and best parameters\n",
    "#     best_models = {}\n",
    "#     best_rmse_scores = {}\n",
    "#     best_parameters = {}\n",
    "\n",
    "#     # Hyperparameter tuning loop\n",
    "#     for model_name, model in models.items():\n",
    "#         param_grid = param_grids[model_name]\n",
    "        \n",
    "#         if param_grid:\n",
    "#             search = GridSearchCV(model, param_grid, scoring='neg_mean_squared_error', cv=5)\n",
    "#             search.fit(X_train, y_train)\n",
    "            \n",
    "#             best_model = search.best_estimator_\n",
    "#             best_rmse = np.sqrt(-search.best_score_)\n",
    "#             best_param = search.best_params_\n",
    "#         else:\n",
    "#             model.fit(X_train, y_train)\n",
    "#             best_model = model\n",
    "#             y_pred = model.predict(X_val)\n",
    "#             best_rmse = np.sqrt(mean_squared_error(y_val, y_pred))\n",
    "#             best_param = None\n",
    "        \n",
    "#         best_models[model_name] = best_model\n",
    "#         best_rmse_scores[model_name] = best_rmse\n",
    "#         best_parameters[model_name] = best_param\n",
    "#         log_message(f\"Best {model_name} RMSE: {best_rmse}\")\n",
    "\n",
    "#     # Find the model with the lowest RMSE\n",
    "#     best_model_name = min(best_rmse_scores, key=best_rmse_scores.get)\n",
    "#     log_message(f\"Best Model: {best_model_name} (RMSE: {best_rmse_scores[best_model_name]})\")\n",
    "\n",
    "#     # Print the best parameters for the best model\n",
    "#     log_message(\"Best Parameters for Best Model:\")\n",
    "#     log_message(best_parameters[best_model_name])\n",
    "\n",
    "#     # # Evaluate the best model on the test data\n",
    "#     # best_model = best_models[best_model_name]\n",
    "#     # y_test_pred = best_model.predict(X_test)\n",
    "#     # test_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
    "#     # print(f\"Test RMSE of Best Model: {test_rmse}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====================== result for random seed: 0 ======================\n",
      "Best Linear Regression RMSE: 51301.201119121564\n",
      "Best Ridge Regression RMSE: 58755.50590564885\n",
      "Best Lasso Regression RMSE: 58757.052847503815\n",
      "Best Decision Tree Regressor RMSE: 52324.53748709445\n",
      "Best Random Forest Regressor RMSE: 48943.680070543705\n",
      "Best Gradient Boosting Regressor RMSE: 48166.72458631268\n",
      "Best AdaBoost Regressor RMSE: 51751.82445959914\n",
      "Best XGBoost Regressor RMSE: 48044.78663199648\n",
      "Best LightGBM Regressor RMSE: 47730.07315938927\n",
      "Best CatBoost Regressor RMSE: 47928.23353969009\n",
      "Best ElasticNet Regression RMSE: 58741.54247311874\n",
      "Best K-Nearest Neighbors RMSE: 51871.33400859439\n",
      "Best Support Vector Regressor RMSE: 59256.06508905296\n",
      "Best Bayesian Ridge Regression RMSE: 58750.163434146205\n",
      "Best Model: LightGBM Regressor (RMSE: 47730.07315938927)\n",
      "Best Parameters for Best Model:\n",
      "{'max_depth': 4, 'n_estimators': 100}\n",
      "\n",
      "====================== result for random seed: 1 ======================\n",
      "Best Linear Regression RMSE: 52759.98521013404\n",
      "Best Ridge Regression RMSE: 59375.21544535748\n",
      "Best Lasso Regression RMSE: 59377.48236292873\n",
      "Best Decision Tree Regressor RMSE: 52591.27326023586\n",
      "Best Random Forest Regressor RMSE: 49242.36247965254\n",
      "Best Gradient Boosting Regressor RMSE: 48644.162792203766\n",
      "Best AdaBoost Regressor RMSE: 52507.00072576875\n",
      "Best XGBoost Regressor RMSE: 48632.99608555747\n",
      "Best LightGBM Regressor RMSE: 48314.70522599315\n",
      "Best CatBoost Regressor RMSE: 48590.127245228636\n",
      "Best ElasticNet Regression RMSE: 59350.79112705265\n",
      "Best K-Nearest Neighbors RMSE: 50685.9994772069\n",
      "Best Support Vector Regressor RMSE: 59944.12952193678\n",
      "Best Bayesian Ridge Regression RMSE: 59357.95291466097\n",
      "Best Model: LightGBM Regressor (RMSE: 48314.70522599315)\n",
      "Best Parameters for Best Model:\n",
      "{'max_depth': 3, 'n_estimators': 200}\n",
      "\n",
      "====================== result for random seed: 2 ======================\n",
      "Best Linear Regression RMSE: 51916.57215413158\n",
      "Best Ridge Regression RMSE: 58769.23070446273\n",
      "Best Lasso Regression RMSE: 58772.39293699059\n",
      "Best Decision Tree Regressor RMSE: 52227.38463385513\n",
      "Best Random Forest Regressor RMSE: 48872.16611207678\n",
      "Best Gradient Boosting Regressor RMSE: 48565.81691059986\n",
      "Best AdaBoost Regressor RMSE: 52310.57582106355\n",
      "Best XGBoost Regressor RMSE: 48322.36291403811\n",
      "Best LightGBM Regressor RMSE: 48177.189201844725\n",
      "Best CatBoost Regressor RMSE: 48180.68013881248\n",
      "Best ElasticNet Regression RMSE: 58754.65544038216\n",
      "Best K-Nearest Neighbors RMSE: 50729.02321940909\n",
      "Best Support Vector Regressor RMSE: 59428.35153302528\n",
      "Best Bayesian Ridge Regression RMSE: 58765.03889744068\n",
      "Best Model: LightGBM Regressor (RMSE: 48177.189201844725)\n",
      "Best Parameters for Best Model:\n",
      "{'max_depth': 4, 'n_estimators': 100}\n",
      "\n",
      "====================== result for random seed: 3 ======================\n",
      "Best Linear Regression RMSE: 54010.09337315412\n",
      "Best Ridge Regression RMSE: 59129.433027663166\n",
      "Best Lasso Regression RMSE: 59131.87257685911\n",
      "Best Decision Tree Regressor RMSE: 51460.14014957498\n",
      "Best Random Forest Regressor RMSE: 48983.475389593645\n",
      "Best Gradient Boosting Regressor RMSE: 48530.935406147604\n",
      "Best AdaBoost Regressor RMSE: 52106.47183064161\n",
      "Best XGBoost Regressor RMSE: 48492.53662639636\n",
      "Best LightGBM Regressor RMSE: 48451.78453414759\n",
      "Best CatBoost Regressor RMSE: 48433.38408071478\n",
      "Best ElasticNet Regression RMSE: 59101.27942877802\n",
      "Best K-Nearest Neighbors RMSE: 51254.208971038344\n",
      "Best Support Vector Regressor RMSE: 59634.19229757995\n",
      "Best Bayesian Ridge Regression RMSE: 59114.16226835696\n",
      "Best Model: CatBoost Regressor (RMSE: 48433.38408071478)\n",
      "Best Parameters for Best Model:\n",
      "{'depth': 6, 'iterations': 200}\n",
      "\n",
      "====================== result for random seed: 4 ======================\n",
      "Best Linear Regression RMSE: 56043.51091501818\n",
      "Best Ridge Regression RMSE: 59263.01923420829\n",
      "Best Lasso Regression RMSE: 59265.81575864962\n",
      "Best Decision Tree Regressor RMSE: 51169.796780373195\n",
      "Best Random Forest Regressor RMSE: 48610.49480545281\n",
      "Best Gradient Boosting Regressor RMSE: 48247.039175197795\n",
      "Best AdaBoost Regressor RMSE: 52132.16819707383\n",
      "Best XGBoost Regressor RMSE: 48237.0963760938\n",
      "Best LightGBM Regressor RMSE: 48042.47100114255\n",
      "Best CatBoost Regressor RMSE: 48181.37032856015\n",
      "Best ElasticNet Regression RMSE: 59246.283208675224\n",
      "Best K-Nearest Neighbors RMSE: 50808.769279233406\n",
      "Best Support Vector Regressor RMSE: 59812.111454111735\n",
      "Best Bayesian Ridge Regression RMSE: 59259.39116580857\n",
      "Best Model: LightGBM Regressor (RMSE: 48042.47100114255)\n",
      "Best Parameters for Best Model:\n",
      "{'max_depth': 5, 'n_estimators': 100}\n",
      "\n",
      "====================== result for random seed: 5 ======================\n",
      "Best Linear Regression RMSE: 55062.87087820001\n",
      "Best Ridge Regression RMSE: 58549.842368837955\n",
      "Best Lasso Regression RMSE: 58553.02514907004\n",
      "Best Decision Tree Regressor RMSE: 51640.56702092551\n",
      "Best Random Forest Regressor RMSE: 49109.34728287381\n",
      "Best Gradient Boosting Regressor RMSE: 48707.17610629881\n",
      "Best AdaBoost Regressor RMSE: 51869.062737577224\n",
      "Best XGBoost Regressor RMSE: 48546.910000118565\n",
      "Best LightGBM Regressor RMSE: 48169.710321140905\n",
      "Best CatBoost Regressor RMSE: 48432.98418845048\n",
      "Best ElasticNet Regression RMSE: 58531.32386724058\n",
      "Best K-Nearest Neighbors RMSE: 51092.012736464174\n",
      "Best Support Vector Regressor RMSE: 59165.52569398745\n",
      "Best Bayesian Ridge Regression RMSE: 58539.700437453634\n",
      "Best Model: LightGBM Regressor (RMSE: 48169.710321140905)\n",
      "Best Parameters for Best Model:\n",
      "{'max_depth': 3, 'n_estimators': 200}\n",
      "\n",
      "====================== result for random seed: 6 ======================\n",
      "Best Linear Regression RMSE: 53240.273188253166\n",
      "Best Ridge Regression RMSE: 59244.7913010658\n",
      "Best Lasso Regression RMSE: 59249.185001716396\n",
      "Best Decision Tree Regressor RMSE: 51236.92198402127\n",
      "Best Random Forest Regressor RMSE: 49056.319993312405\n",
      "Best Gradient Boosting Regressor RMSE: 48418.146460190954\n",
      "Best AdaBoost Regressor RMSE: 52632.32552395812\n",
      "Best XGBoost Regressor RMSE: 48363.7212501464\n",
      "Best LightGBM Regressor RMSE: 48346.73093704092\n",
      "Best CatBoost Regressor RMSE: 48353.39993195377\n",
      "Best ElasticNet Regression RMSE: 59216.56868594514\n",
      "Best K-Nearest Neighbors RMSE: 51377.670790176984\n",
      "Best Support Vector Regressor RMSE: 59833.092489630726\n",
      "Best Bayesian Ridge Regression RMSE: 59240.51829714663\n",
      "Best Model: LightGBM Regressor (RMSE: 48346.73093704092)\n",
      "Best Parameters for Best Model:\n",
      "{'max_depth': 4, 'n_estimators': 200}\n",
      "\n",
      "====================== result for random seed: 7 ======================\n",
      "Best Linear Regression RMSE: 53794.14453404392\n",
      "Best Ridge Regression RMSE: 59695.17411212434\n",
      "Best Lasso Regression RMSE: 59697.82607755488\n",
      "Best Decision Tree Regressor RMSE: 52153.436065262205\n",
      "Best Random Forest Regressor RMSE: 49103.203489687534\n",
      "Best Gradient Boosting Regressor RMSE: 48589.360381629056\n",
      "Best AdaBoost Regressor RMSE: 52324.557151641144\n",
      "Best XGBoost Regressor RMSE: 48431.93541337454\n",
      "Best LightGBM Regressor RMSE: 48272.755987406475\n",
      "Best CatBoost Regressor RMSE: 48545.62841805171\n",
      "Best ElasticNet Regression RMSE: 59679.107877667455\n",
      "Best K-Nearest Neighbors RMSE: 52188.06627360589\n",
      "Best Support Vector Regressor RMSE: 60184.04054510384\n",
      "Best Bayesian Ridge Regression RMSE: 59688.27023283379\n",
      "Best Model: LightGBM Regressor (RMSE: 48272.755987406475)\n",
      "Best Parameters for Best Model:\n",
      "{'max_depth': 4, 'n_estimators': 100}\n",
      "\n",
      "====================== result for random seed: 8 ======================\n",
      "Best Linear Regression RMSE: 51471.22157392744\n",
      "Best Ridge Regression RMSE: 58761.28172066841\n",
      "Best Lasso Regression RMSE: 58764.076865793184\n",
      "Best Decision Tree Regressor RMSE: 51176.92962466767\n",
      "Best Random Forest Regressor RMSE: 48993.215166871545\n",
      "Best Gradient Boosting Regressor RMSE: 48511.179688830445\n",
      "Best AdaBoost Regressor RMSE: 52054.27703607221\n",
      "Best XGBoost Regressor RMSE: 48451.473848994254\n",
      "Best LightGBM Regressor RMSE: 48069.03630534622\n",
      "Best CatBoost Regressor RMSE: 48355.99149167151\n",
      "Best ElasticNet Regression RMSE: 58751.18343466346\n",
      "Best K-Nearest Neighbors RMSE: 51524.21049537611\n",
      "Best Support Vector Regressor RMSE: 59537.53481851555\n",
      "Best Bayesian Ridge Regression RMSE: 58753.69808341564\n",
      "Best Model: LightGBM Regressor (RMSE: 48069.03630534622)\n",
      "Best Parameters for Best Model:\n",
      "{'max_depth': 4, 'n_estimators': 200}\n",
      "\n",
      "====================== result for random seed: 9 ======================\n",
      "Best Linear Regression RMSE: 55197.48395166444\n",
      "Best Ridge Regression RMSE: 58594.66546434257\n",
      "Best Lasso Regression RMSE: 58598.6477186199\n",
      "Best Decision Tree Regressor RMSE: 51643.41365781981\n",
      "Best Random Forest Regressor RMSE: 49083.39540932724\n",
      "Best Gradient Boosting Regressor RMSE: 48156.79700226338\n",
      "Best AdaBoost Regressor RMSE: 51692.1855094279\n",
      "Best XGBoost Regressor RMSE: 47986.270845227315\n",
      "Best LightGBM Regressor RMSE: 48006.31879139943\n",
      "Best CatBoost Regressor RMSE: 48064.39521808363\n",
      "Best ElasticNet Regression RMSE: 58576.973597790464\n",
      "Best K-Nearest Neighbors RMSE: 52099.16738555916\n",
      "Best Support Vector Regressor RMSE: 59308.57464950078\n",
      "Best Bayesian Ridge Regression RMSE: 58592.803526243886\n",
      "Best Model: XGBoost Regressor (RMSE: 47986.270845227315)\n",
      "Best Parameters for Best Model:\n",
      "{'max_depth': 4, 'n_estimators': 50}\n",
      "\n",
      "====================== result for random seed: 10 ======================\n",
      "Best Linear Regression RMSE: 53679.12785515369\n",
      "Best Ridge Regression RMSE: 59123.37303876543\n",
      "Best Lasso Regression RMSE: 59125.38773201908\n",
      "Best Decision Tree Regressor RMSE: 51755.112631508884\n",
      "Best Random Forest Regressor RMSE: 49157.88148121123\n",
      "Best Gradient Boosting Regressor RMSE: 48686.635540429896\n",
      "Best AdaBoost Regressor RMSE: 52422.4198719157\n",
      "Best XGBoost Regressor RMSE: 48600.73154816777\n",
      "Best LightGBM Regressor RMSE: 48062.210625054504\n",
      "Best CatBoost Regressor RMSE: 48488.020829828776\n",
      "Best ElasticNet Regression RMSE: 59100.13221631492\n",
      "Best K-Nearest Neighbors RMSE: 51241.41985239874\n",
      "Best Support Vector Regressor RMSE: 59610.03512270931\n",
      "Best Bayesian Ridge Regression RMSE: 59125.81582225008\n",
      "Best Model: LightGBM Regressor (RMSE: 48062.210625054504)\n",
      "Best Parameters for Best Model:\n",
      "{'max_depth': 4, 'n_estimators': 200}\n",
      "\n",
      "====================== result for random seed: 11 ======================\n",
      "Best Linear Regression RMSE: 52667.75079775604\n",
      "Best Ridge Regression RMSE: 59212.52917025964\n",
      "Best Lasso Regression RMSE: 59215.402174182826\n",
      "Best Decision Tree Regressor RMSE: 51307.765634717056\n",
      "Best Random Forest Regressor RMSE: 48884.08383488556\n",
      "Best Gradient Boosting Regressor RMSE: 48070.87439438196\n",
      "Best AdaBoost Regressor RMSE: 52553.43232373949\n",
      "Best XGBoost Regressor RMSE: 48160.11786920091\n",
      "Best LightGBM Regressor RMSE: 48354.86494362688\n",
      "Best CatBoost Regressor RMSE: 48323.70002628138\n",
      "Best ElasticNet Regression RMSE: 59196.056478730345\n",
      "Best K-Nearest Neighbors RMSE: 51488.99757954003\n",
      "Best Support Vector Regressor RMSE: 59801.08085374432\n",
      "Best Bayesian Ridge Regression RMSE: 59205.971729246616\n",
      "Best Model: Gradient Boosting Regressor (RMSE: 48070.87439438196)\n",
      "Best Parameters for Best Model:\n",
      "{'max_depth': 4, 'n_estimators': 100}\n",
      "\n",
      "====================== result for random seed: 12 ======================\n",
      "Best Linear Regression RMSE: 55131.97779735436\n",
      "Best Ridge Regression RMSE: 58685.0390320529\n",
      "Best Lasso Regression RMSE: 58686.17197132767\n",
      "Best Decision Tree Regressor RMSE: 50221.76402556858\n",
      "Best Random Forest Regressor RMSE: 48276.054306826096\n",
      "Best Gradient Boosting Regressor RMSE: 47831.08437516212\n",
      "Best AdaBoost Regressor RMSE: 51493.134497020365\n",
      "Best XGBoost Regressor RMSE: 47861.54310500059\n",
      "Best LightGBM Regressor RMSE: 47622.60290316981\n",
      "Best CatBoost Regressor RMSE: 47929.000740558215\n",
      "Best ElasticNet Regression RMSE: 58681.80188040264\n",
      "Best K-Nearest Neighbors RMSE: 50740.79984740485\n",
      "Best Support Vector Regressor RMSE: 59432.84412980737\n",
      "Best Bayesian Ridge Regression RMSE: 58690.19427955184\n",
      "Best Model: LightGBM Regressor (RMSE: 47622.60290316981)\n",
      "Best Parameters for Best Model:\n",
      "{'max_depth': 5, 'n_estimators': 100}\n",
      "\n",
      "====================== result for random seed: 13 ======================\n",
      "Best Linear Regression RMSE: 54817.55612600739\n",
      "Best Ridge Regression RMSE: 59516.10609695739\n",
      "Best Lasso Regression RMSE: 59519.28336865058\n",
      "Best Decision Tree Regressor RMSE: 51973.87964483839\n",
      "Best Random Forest Regressor RMSE: 49221.51061297476\n",
      "Best Gradient Boosting Regressor RMSE: 48663.65513317056\n",
      "Best AdaBoost Regressor RMSE: 52593.37310622975\n",
      "Best XGBoost Regressor RMSE: 48288.61141419331\n",
      "Best LightGBM Regressor RMSE: 48360.31562232271\n",
      "Best CatBoost Regressor RMSE: 48573.735030157804\n",
      "Best ElasticNet Regression RMSE: 59497.387953233585\n",
      "Best K-Nearest Neighbors RMSE: 50968.56972309003\n",
      "Best Support Vector Regressor RMSE: 60100.24529119838\n",
      "Best Bayesian Ridge Regression RMSE: 59509.56802668272\n",
      "Best Model: XGBoost Regressor (RMSE: 48288.61141419331)\n",
      "Best Parameters for Best Model:\n",
      "{'max_depth': 4, 'n_estimators': 50}\n",
      "\n",
      "====================== result for random seed: 14 ======================\n",
      "Best Linear Regression RMSE: 56269.610433131915\n",
      "Best Ridge Regression RMSE: 59543.87436779948\n",
      "Best Lasso Regression RMSE: 59547.14445982369\n",
      "Best Decision Tree Regressor RMSE: 51628.31225271685\n",
      "Best Random Forest Regressor RMSE: 49376.5253661515\n",
      "Best Gradient Boosting Regressor RMSE: 48649.59894936855\n",
      "Best AdaBoost Regressor RMSE: 52276.58028234681\n",
      "Best XGBoost Regressor RMSE: 48780.412726298404\n",
      "Best LightGBM Regressor RMSE: 48867.54977505414\n",
      "Best CatBoost Regressor RMSE: 48938.455354000434\n",
      "Best ElasticNet Regression RMSE: 59523.61844106217\n",
      "Best K-Nearest Neighbors RMSE: 51198.30556195467\n",
      "Best Support Vector Regressor RMSE: 60125.04662447518\n",
      "Best Bayesian Ridge Regression RMSE: 59529.46981245661\n",
      "Best Model: Gradient Boosting Regressor (RMSE: 48649.59894936855)\n",
      "Best Parameters for Best Model:\n",
      "{'max_depth': 4, 'n_estimators': 100}\n",
      "\n",
      "====================== result for random seed: 15 ======================\n",
      "Best Linear Regression RMSE: 55562.82876106898\n",
      "Best Ridge Regression RMSE: 58935.936295662475\n",
      "Best Lasso Regression RMSE: 58937.86259831166\n",
      "Best Decision Tree Regressor RMSE: 50991.34352707317\n",
      "Best Random Forest Regressor RMSE: 48528.966820702575\n",
      "Best Gradient Boosting Regressor RMSE: 47966.834235215145\n",
      "Best AdaBoost Regressor RMSE: 51677.70662112932\n",
      "Best XGBoost Regressor RMSE: 48253.714604426306\n",
      "Best LightGBM Regressor RMSE: 47715.4189473583\n",
      "Best CatBoost Regressor RMSE: 47700.849015960535\n",
      "Best ElasticNet Regression RMSE: 58926.240911793204\n",
      "Best K-Nearest Neighbors RMSE: 50803.430386453285\n",
      "Best Support Vector Regressor RMSE: 59435.52308020716\n",
      "Best Bayesian Ridge Regression RMSE: 58942.84118667286\n",
      "Best Model: CatBoost Regressor (RMSE: 47700.849015960535)\n",
      "Best Parameters for Best Model:\n",
      "{'depth': 4, 'iterations': 100}\n",
      "\n",
      "====================== result for random seed: 16 ======================\n",
      "Best Linear Regression RMSE: 54567.97925711791\n",
      "Best Ridge Regression RMSE: 58920.818270246644\n",
      "Best Lasso Regression RMSE: 58923.47748349741\n",
      "Best Decision Tree Regressor RMSE: 51182.68583563375\n",
      "Best Random Forest Regressor RMSE: 48933.164422171365\n",
      "Best Gradient Boosting Regressor RMSE: 48342.69023980384\n",
      "Best AdaBoost Regressor RMSE: 52063.611929093335\n",
      "Best XGBoost Regressor RMSE: 48322.8633130713\n",
      "Best LightGBM Regressor RMSE: 48190.289430876925\n",
      "Best CatBoost Regressor RMSE: 48321.30033191777\n",
      "Best ElasticNet Regression RMSE: 58902.07225662043\n",
      "Best K-Nearest Neighbors RMSE: 51590.86525666157\n",
      "Best Support Vector Regressor RMSE: 59480.18221901797\n",
      "Best Bayesian Ridge Regression RMSE: 58932.70414297779\n",
      "Best Model: LightGBM Regressor (RMSE: 48190.289430876925)\n",
      "Best Parameters for Best Model:\n",
      "{'max_depth': 4, 'n_estimators': 100}\n",
      "\n",
      "====================== result for random seed: 17 ======================\n",
      "Best Linear Regression RMSE: 54844.11320078523\n",
      "Best Ridge Regression RMSE: 59097.020516479046\n",
      "Best Lasso Regression RMSE: 59098.741983118874\n",
      "Best Decision Tree Regressor RMSE: 51702.492622335434\n",
      "Best Random Forest Regressor RMSE: 48830.208188367535\n",
      "Best Gradient Boosting Regressor RMSE: 48426.668492047495\n",
      "Best AdaBoost Regressor RMSE: 52003.44956228925\n",
      "Best XGBoost Regressor RMSE: 48239.76505147582\n",
      "Best LightGBM Regressor RMSE: 48221.07584158664\n",
      "Best CatBoost Regressor RMSE: 48229.60495445529\n",
      "Best ElasticNet Regression RMSE: 59089.971032906644\n",
      "Best K-Nearest Neighbors RMSE: 50959.36030919993\n",
      "Best Support Vector Regressor RMSE: 59596.465134472535\n",
      "Best Bayesian Ridge Regression RMSE: 59104.71837939175\n",
      "Best Model: LightGBM Regressor (RMSE: 48221.07584158664)\n",
      "Best Parameters for Best Model:\n",
      "{'max_depth': 4, 'n_estimators': 100}\n",
      "\n",
      "====================== result for random seed: 18 ======================\n",
      "Best Linear Regression RMSE: 52335.689688205384\n",
      "Best Ridge Regression RMSE: 59132.37582189798\n",
      "Best Lasso Regression RMSE: 59135.26553950897\n",
      "Best Decision Tree Regressor RMSE: 51083.89881745251\n",
      "Best Random Forest Regressor RMSE: 48573.09212541059\n",
      "Best Gradient Boosting Regressor RMSE: 48313.394171500804\n",
      "Best AdaBoost Regressor RMSE: 52218.915545716154\n",
      "Best XGBoost Regressor RMSE: 48207.134744865645\n",
      "Best LightGBM Regressor RMSE: 48020.89568729042\n",
      "Best CatBoost Regressor RMSE: 48056.24174545903\n",
      "Best ElasticNet Regression RMSE: 59104.12225754925\n",
      "Best K-Nearest Neighbors RMSE: 51949.19739700012\n",
      "Best Support Vector Regressor RMSE: 59693.379684263586\n",
      "Best Bayesian Ridge Regression RMSE: 59123.790734204595\n",
      "Best Model: LightGBM Regressor (RMSE: 48020.89568729042)\n",
      "Best Parameters for Best Model:\n",
      "{'max_depth': 4, 'n_estimators': 100}\n",
      "\n",
      "====================== result for random seed: 19 ======================\n",
      "Best Linear Regression RMSE: 54387.044096285375\n",
      "Best Ridge Regression RMSE: 59307.75072674522\n",
      "Best Lasso Regression RMSE: 59311.987686823006\n",
      "Best Decision Tree Regressor RMSE: 51090.25355537068\n",
      "Best Random Forest Regressor RMSE: 48749.53739250486\n",
      "Best Gradient Boosting Regressor RMSE: 48482.36954660637\n",
      "Best AdaBoost Regressor RMSE: 52070.22044549219\n",
      "Best XGBoost Regressor RMSE: 48553.78599253042\n",
      "Best LightGBM Regressor RMSE: 48232.71563917526\n",
      "Best CatBoost Regressor RMSE: 48162.04736220727\n",
      "Best ElasticNet Regression RMSE: 59260.653265848785\n",
      "Best K-Nearest Neighbors RMSE: 51409.87806903148\n",
      "Best Support Vector Regressor RMSE: 59830.78249546463\n",
      "Best Bayesian Ridge Regression RMSE: 59268.34525411303\n",
      "Best Model: CatBoost Regressor (RMSE: 48162.04736220727)\n",
      "Best Parameters for Best Model:\n",
      "{'depth': 4, 'iterations': 200}\n",
      "\n",
      "====================== result for random seed: 20 ======================\n",
      "Best Linear Regression RMSE: 56315.36440244962\n",
      "Best Ridge Regression RMSE: 58420.55100126277\n",
      "Best Lasso Regression RMSE: 58422.623600537605\n",
      "Best Decision Tree Regressor RMSE: 50324.27591050953\n",
      "Best Random Forest Regressor RMSE: 48342.46994529995\n",
      "Best Gradient Boosting Regressor RMSE: 47743.84064560564\n",
      "Best AdaBoost Regressor RMSE: 51490.54452101776\n",
      "Best XGBoost Regressor RMSE: 47851.32480053654\n",
      "Best LightGBM Regressor RMSE: 47759.851486345025\n",
      "Best CatBoost Regressor RMSE: 47716.05842917898\n",
      "Best ElasticNet Regression RMSE: 58411.14726800377\n",
      "Best K-Nearest Neighbors RMSE: 50772.680132684414\n",
      "Best Support Vector Regressor RMSE: 58903.93619392691\n",
      "Best Bayesian Ridge Regression RMSE: 58424.61744149779\n",
      "Best Model: CatBoost Regressor (RMSE: 47716.05842917898)\n",
      "Best Parameters for Best Model:\n",
      "{'depth': 4, 'iterations': 200}\n",
      "\n",
      "====================== result for random seed: 21 ======================\n",
      "Best Linear Regression RMSE: 54521.37416592785\n",
      "Best Ridge Regression RMSE: 58921.76993277758\n",
      "Best Lasso Regression RMSE: 58923.18041266658\n",
      "Best Decision Tree Regressor RMSE: 51488.48121528492\n",
      "Best Random Forest Regressor RMSE: 48731.13672970277\n",
      "Best Gradient Boosting Regressor RMSE: 48158.39496603758\n",
      "Best AdaBoost Regressor RMSE: 52040.59210102732\n",
      "Best XGBoost Regressor RMSE: 48163.36318715883\n",
      "Best LightGBM Regressor RMSE: 47771.37229499153\n",
      "Best CatBoost Regressor RMSE: 48059.414486595364\n",
      "Best ElasticNet Regression RMSE: 58890.710780601\n",
      "Best K-Nearest Neighbors RMSE: 51367.85653365456\n",
      "Best Support Vector Regressor RMSE: 59413.620366951225\n",
      "Best Bayesian Ridge Regression RMSE: 58907.15244078905\n",
      "Best Model: LightGBM Regressor (RMSE: 47771.37229499153)\n",
      "Best Parameters for Best Model:\n",
      "{'max_depth': 4, 'n_estimators': 100}\n",
      "\n",
      "====================== result for random seed: 22 ======================\n",
      "Best Linear Regression RMSE: 54148.193092742134\n",
      "Best Ridge Regression RMSE: 58943.50443390115\n",
      "Best Lasso Regression RMSE: 58946.77218282311\n",
      "Best Decision Tree Regressor RMSE: 50568.07430491052\n",
      "Best Random Forest Regressor RMSE: 48165.41625577727\n",
      "Best Gradient Boosting Regressor RMSE: 47925.73491259602\n",
      "Best AdaBoost Regressor RMSE: 52005.554043527576\n",
      "Best XGBoost Regressor RMSE: 47899.54233081829\n",
      "Best LightGBM Regressor RMSE: 47912.426655872165\n",
      "Best CatBoost Regressor RMSE: 47886.458089757696\n",
      "Best ElasticNet Regression RMSE: 58926.40190943296\n",
      "Best K-Nearest Neighbors RMSE: 50922.14379240132\n",
      "Best Support Vector Regressor RMSE: 59587.94856389373\n",
      "Best Bayesian Ridge Regression RMSE: 58942.805178491406\n",
      "Best Model: CatBoost Regressor (RMSE: 47886.458089757696)\n",
      "Best Parameters for Best Model:\n",
      "{'depth': 4, 'iterations': 100}\n",
      "\n",
      "====================== result for random seed: 23 ======================\n",
      "Best Linear Regression RMSE: 54990.366699793914\n",
      "Best Ridge Regression RMSE: 58927.54192690689\n",
      "Best Lasso Regression RMSE: 58930.519841308545\n",
      "Best Decision Tree Regressor RMSE: 50892.68634716596\n",
      "Best Random Forest Regressor RMSE: 48478.167814935136\n",
      "Best Gradient Boosting Regressor RMSE: 48239.89647762683\n",
      "Best AdaBoost Regressor RMSE: 51565.91485114815\n",
      "Best XGBoost Regressor RMSE: 48321.194659103465\n",
      "Best LightGBM Regressor RMSE: 48085.734299967466\n",
      "Best CatBoost Regressor RMSE: 48155.67476985161\n",
      "Best ElasticNet Regression RMSE: 58892.35628837373\n",
      "Best K-Nearest Neighbors RMSE: 50531.91872761065\n",
      "Best Support Vector Regressor RMSE: 59434.852461460374\n",
      "Best Bayesian Ridge Regression RMSE: 58900.2577577958\n",
      "Best Model: LightGBM Regressor (RMSE: 48085.734299967466)\n",
      "Best Parameters for Best Model:\n",
      "{'max_depth': 3, 'n_estimators': 200}\n",
      "\n",
      "====================== result for random seed: 24 ======================\n",
      "Best Linear Regression RMSE: 54584.16854048158\n",
      "Best Ridge Regression RMSE: 59476.10889139521\n",
      "Best Lasso Regression RMSE: 59479.56069251373\n",
      "Best Decision Tree Regressor RMSE: 51578.82900540099\n",
      "Best Random Forest Regressor RMSE: 49343.018894896086\n",
      "Best Gradient Boosting Regressor RMSE: 49030.43337895523\n",
      "Best AdaBoost Regressor RMSE: 52510.655029930705\n",
      "Best XGBoost Regressor RMSE: 48827.571099219196\n",
      "Best LightGBM Regressor RMSE: 48652.002101006394\n",
      "Best CatBoost Regressor RMSE: 48947.085413128196\n",
      "Best ElasticNet Regression RMSE: 59453.4038775849\n",
      "Best K-Nearest Neighbors RMSE: 51527.80973998494\n",
      "Best Support Vector Regressor RMSE: 59973.34299221494\n",
      "Best Bayesian Ridge Regression RMSE: 59472.19798807943\n",
      "Best Model: LightGBM Regressor (RMSE: 48652.002101006394)\n",
      "Best Parameters for Best Model:\n",
      "{'max_depth': 4, 'n_estimators': 100}\n",
      "\n",
      "====================== result for random seed: 25 ======================\n",
      "Best Linear Regression RMSE: 53551.28559927767\n",
      "Best Ridge Regression RMSE: 59183.94773470418\n",
      "Best Lasso Regression RMSE: 59185.90681521999\n",
      "Best Decision Tree Regressor RMSE: 51933.459813694106\n",
      "Best Random Forest Regressor RMSE: 49282.309411267444\n",
      "Best Gradient Boosting Regressor RMSE: 48761.390211854494\n",
      "Best AdaBoost Regressor RMSE: 52338.760322243106\n",
      "Best XGBoost Regressor RMSE: 48805.80370493753\n",
      "Best LightGBM Regressor RMSE: 48674.92745955008\n",
      "Best CatBoost Regressor RMSE: 48723.49669552076\n",
      "Best ElasticNet Regression RMSE: 59164.14642025159\n",
      "Best K-Nearest Neighbors RMSE: 51105.342371878636\n",
      "Best Support Vector Regressor RMSE: 59796.90965470468\n",
      "Best Bayesian Ridge Regression RMSE: 59169.62033326129\n",
      "Best Model: LightGBM Regressor (RMSE: 48674.92745955008)\n",
      "Best Parameters for Best Model:\n",
      "{'max_depth': 4, 'n_estimators': 100}\n",
      "\n",
      "====================== result for random seed: 26 ======================\n",
      "Best Linear Regression RMSE: 51282.97598417913\n",
      "Best Ridge Regression RMSE: 58460.928381185\n",
      "Best Lasso Regression RMSE: 58464.20338727454\n",
      "Best Decision Tree Regressor RMSE: 51970.682391681716\n",
      "Best Random Forest Regressor RMSE: 48602.797691706204\n",
      "Best Gradient Boosting Regressor RMSE: 48230.079323962535\n",
      "Best AdaBoost Regressor RMSE: 51218.59744012881\n",
      "Best XGBoost Regressor RMSE: 48015.5071679528\n",
      "Best LightGBM Regressor RMSE: 47585.54965645435\n",
      "Best CatBoost Regressor RMSE: 47871.32608411871\n",
      "Best ElasticNet Regression RMSE: 58440.502248963305\n",
      "Best K-Nearest Neighbors RMSE: 50327.94259010475\n",
      "Best Support Vector Regressor RMSE: 58944.69681875763\n",
      "Best Bayesian Ridge Regression RMSE: 58456.71558894837\n",
      "Best Model: LightGBM Regressor (RMSE: 47585.54965645435)\n",
      "Best Parameters for Best Model:\n",
      "{'max_depth': 3, 'n_estimators': 200}\n",
      "\n",
      "====================== result for random seed: 27 ======================\n",
      "Best Linear Regression RMSE: 53275.938629680415\n",
      "Best Ridge Regression RMSE: 59172.55418632569\n",
      "Best Lasso Regression RMSE: 59172.75990673731\n",
      "Best Decision Tree Regressor RMSE: 51363.11631970336\n",
      "Best Random Forest Regressor RMSE: 48976.73745002647\n",
      "Best Gradient Boosting Regressor RMSE: 48290.1725058128\n",
      "Best AdaBoost Regressor RMSE: 52103.29030563778\n",
      "Best XGBoost Regressor RMSE: 48276.60141210812\n",
      "Best LightGBM Regressor RMSE: 48117.112746464125\n",
      "Best CatBoost Regressor RMSE: 48336.93390681764\n",
      "Best ElasticNet Regression RMSE: 59156.389599264374\n",
      "Best K-Nearest Neighbors RMSE: 51820.24864412155\n",
      "Best Support Vector Regressor RMSE: 59720.353287695994\n",
      "Best Bayesian Ridge Regression RMSE: 59163.38467118514\n",
      "Best Model: LightGBM Regressor (RMSE: 48117.112746464125)\n",
      "Best Parameters for Best Model:\n",
      "{'max_depth': 5, 'n_estimators': 100}\n",
      "\n",
      "====================== result for random seed: 28 ======================\n",
      "Best Linear Regression RMSE: 53742.803164461\n",
      "Best Ridge Regression RMSE: 58881.77852264603\n",
      "Best Lasso Regression RMSE: 58885.193451652\n",
      "Best Decision Tree Regressor RMSE: 51574.78380488724\n",
      "Best Random Forest Regressor RMSE: 49131.96194077766\n",
      "Best Gradient Boosting Regressor RMSE: 48458.60689081267\n",
      "Best AdaBoost Regressor RMSE: 52382.89036677153\n",
      "Best XGBoost Regressor RMSE: 48249.647498506645\n",
      "Best LightGBM Regressor RMSE: 48175.69577225872\n",
      "Best CatBoost Regressor RMSE: 48265.93310512246\n",
      "Best ElasticNet Regression RMSE: 58848.53265791998\n",
      "Best K-Nearest Neighbors RMSE: 50967.877198962626\n",
      "Best Support Vector Regressor RMSE: 59369.07376887761\n",
      "Best Bayesian Ridge Regression RMSE: 58863.05815639237\n",
      "Best Model: LightGBM Regressor (RMSE: 48175.69577225872)\n",
      "Best Parameters for Best Model:\n",
      "{'max_depth': 4, 'n_estimators': 100}\n",
      "\n",
      "====================== result for random seed: 29 ======================\n",
      "Best Linear Regression RMSE: 53967.669508069084\n",
      "Best Ridge Regression RMSE: 58809.51403587458\n",
      "Best Lasso Regression RMSE: 58810.89438499224\n",
      "Best Decision Tree Regressor RMSE: 51751.1559980119\n",
      "Best Random Forest Regressor RMSE: 48697.547038777964\n",
      "Best Gradient Boosting Regressor RMSE: 48182.301537030784\n",
      "Best AdaBoost Regressor RMSE: 51250.12477742625\n",
      "Best XGBoost Regressor RMSE: 48004.83430716182\n",
      "Best LightGBM Regressor RMSE: 47815.958466208576\n",
      "Best CatBoost Regressor RMSE: 47891.084158401696\n",
      "Best ElasticNet Regression RMSE: 58803.67497754481\n",
      "Best K-Nearest Neighbors RMSE: 51317.76853842605\n",
      "Best Support Vector Regressor RMSE: 59476.25643818539\n",
      "Best Bayesian Ridge Regression RMSE: 58811.02538319857\n",
      "Best Model: LightGBM Regressor (RMSE: 47815.958466208576)\n",
      "Best Parameters for Best Model:\n",
      "{'max_depth': 5, 'n_estimators': 100}\n",
      "\n",
      "====================== result for random seed: 30 ======================\n",
      "Best Linear Regression RMSE: 54779.72383822282\n",
      "Best Ridge Regression RMSE: 58835.28373853592\n",
      "Best Lasso Regression RMSE: 58837.248423636614\n",
      "Best Decision Tree Regressor RMSE: 50725.15649442082\n",
      "Best Random Forest Regressor RMSE: 48838.25051984405\n",
      "Best Gradient Boosting Regressor RMSE: 48225.201933877695\n",
      "Best AdaBoost Regressor RMSE: 52076.34788849416\n",
      "Best XGBoost Regressor RMSE: 48220.334459960424\n",
      "Best LightGBM Regressor RMSE: 48290.60555926696\n",
      "Best CatBoost Regressor RMSE: 48252.08373326098\n",
      "Best ElasticNet Regression RMSE: 58823.93425269699\n",
      "Best K-Nearest Neighbors RMSE: 51188.656768920024\n",
      "Best Support Vector Regressor RMSE: 59459.415736904266\n",
      "Best Bayesian Ridge Regression RMSE: 58831.387109131916\n",
      "Best Model: XGBoost Regressor (RMSE: 48220.334459960424)\n",
      "Best Parameters for Best Model:\n",
      "{'max_depth': 4, 'n_estimators': 50}\n",
      "\n",
      "====================== result for random seed: 31 ======================\n",
      "Best Linear Regression RMSE: 53798.44889413549\n",
      "Best Ridge Regression RMSE: 58640.63644532704\n",
      "Best Lasso Regression RMSE: 58641.84654159423\n",
      "Best Decision Tree Regressor RMSE: 51614.34837718224\n",
      "Best Random Forest Regressor RMSE: 48843.78260640418\n",
      "Best Gradient Boosting Regressor RMSE: 48491.05561280369\n",
      "Best AdaBoost Regressor RMSE: 51771.81540090239\n",
      "Best XGBoost Regressor RMSE: 48335.05262871267\n",
      "Best LightGBM Regressor RMSE: 48030.39207302744\n",
      "Best CatBoost Regressor RMSE: 48215.20538217724\n",
      "Best ElasticNet Regression RMSE: 58630.70057949527\n",
      "Best K-Nearest Neighbors RMSE: 51254.63195489862\n",
      "Best Support Vector Regressor RMSE: 59274.23380586186\n",
      "Best Bayesian Ridge Regression RMSE: 58637.10631087685\n",
      "Best Model: LightGBM Regressor (RMSE: 48030.39207302744)\n",
      "Best Parameters for Best Model:\n",
      "{'max_depth': 4, 'n_estimators': 100}\n",
      "\n",
      "====================== result for random seed: 32 ======================\n",
      "Best Linear Regression RMSE: 53721.929060002425\n",
      "Best Ridge Regression RMSE: 58621.17558909896\n",
      "Best Lasso Regression RMSE: 58624.25545014164\n",
      "Best Decision Tree Regressor RMSE: 50862.2314969695\n",
      "Best Random Forest Regressor RMSE: 48626.48150311829\n",
      "Best Gradient Boosting Regressor RMSE: 48113.1088106147\n",
      "Best AdaBoost Regressor RMSE: 51802.42727795832\n",
      "Best XGBoost Regressor RMSE: 48184.306917318194\n",
      "Best LightGBM Regressor RMSE: 48009.259343493366\n",
      "Best CatBoost Regressor RMSE: 48063.855604574965\n",
      "Best ElasticNet Regression RMSE: 58600.56130140523\n",
      "Best K-Nearest Neighbors RMSE: 51168.727524925715\n",
      "Best Support Vector Regressor RMSE: 59111.093216348614\n",
      "Best Bayesian Ridge Regression RMSE: 58623.578618228945\n",
      "Best Model: LightGBM Regressor (RMSE: 48009.259343493366)\n",
      "Best Parameters for Best Model:\n",
      "{'max_depth': 4, 'n_estimators': 100}\n",
      "\n",
      "====================== result for random seed: 33 ======================\n",
      "Best Linear Regression RMSE: 53684.16095792597\n",
      "Best Ridge Regression RMSE: 59123.47729555521\n",
      "Best Lasso Regression RMSE: 59125.76003839441\n",
      "Best Decision Tree Regressor RMSE: 50973.83640787608\n",
      "Best Random Forest Regressor RMSE: 49096.00523799858\n",
      "Best Gradient Boosting Regressor RMSE: 48492.18198512044\n",
      "Best AdaBoost Regressor RMSE: 52379.291409888174\n",
      "Best XGBoost Regressor RMSE: 48451.36514299178\n",
      "Best LightGBM Regressor RMSE: 48581.98067383731\n",
      "Best CatBoost Regressor RMSE: 48616.33317478433\n",
      "Best ElasticNet Regression RMSE: 59114.14317163907\n",
      "Best K-Nearest Neighbors RMSE: 51624.960691803026\n",
      "Best Support Vector Regressor RMSE: 59681.211228640444\n",
      "Best Bayesian Ridge Regression RMSE: 59123.20872733339\n",
      "Best Model: XGBoost Regressor (RMSE: 48451.36514299178)\n",
      "Best Parameters for Best Model:\n",
      "{'max_depth': 5, 'n_estimators': 50}\n",
      "\n",
      "====================== result for random seed: 34 ======================\n",
      "Best Linear Regression RMSE: 54747.21327714142\n",
      "Best Ridge Regression RMSE: 58794.382581216814\n",
      "Best Lasso Regression RMSE: 58795.4319457401\n",
      "Best Decision Tree Regressor RMSE: 50732.639576805996\n",
      "Best Random Forest Regressor RMSE: 48820.77155358562\n",
      "Best Gradient Boosting Regressor RMSE: 47723.55791073063\n",
      "Best AdaBoost Regressor RMSE: 51853.86693761458\n",
      "Best XGBoost Regressor RMSE: 47844.07445179015\n",
      "Best LightGBM Regressor RMSE: 47776.10630358249\n",
      "Best CatBoost Regressor RMSE: 47882.17243693785\n",
      "Best ElasticNet Regression RMSE: 58775.80534289657\n",
      "Best K-Nearest Neighbors RMSE: 51006.60524015517\n",
      "Best Support Vector Regressor RMSE: 59242.739443943974\n",
      "Best Bayesian Ridge Regression RMSE: 58785.707369884934\n",
      "Best Model: Gradient Boosting Regressor (RMSE: 47723.55791073063)\n",
      "Best Parameters for Best Model:\n",
      "{'max_depth': 4, 'n_estimators': 100}\n",
      "\n",
      "====================== result for random seed: 35 ======================\n",
      "Best Linear Regression RMSE: 54173.34787862214\n",
      "Best Ridge Regression RMSE: 58952.981758959526\n",
      "Best Lasso Regression RMSE: 58954.56767543687\n",
      "Best Decision Tree Regressor RMSE: 51051.599954213736\n",
      "Best Random Forest Regressor RMSE: 48947.197630934395\n",
      "Best Gradient Boosting Regressor RMSE: 48206.18290464139\n",
      "Best AdaBoost Regressor RMSE: 52132.60083492461\n",
      "Best XGBoost Regressor RMSE: 48002.366085525726\n",
      "Best LightGBM Regressor RMSE: 47811.72021748058\n",
      "Best CatBoost Regressor RMSE: 47945.368278671944\n",
      "Best ElasticNet Regression RMSE: 58938.50329454591\n",
      "Best K-Nearest Neighbors RMSE: 49987.49913548859\n",
      "Best Support Vector Regressor RMSE: 59484.27386166159\n",
      "Best Bayesian Ridge Regression RMSE: 58950.28488275798\n",
      "Best Model: LightGBM Regressor (RMSE: 47811.72021748058)\n",
      "Best Parameters for Best Model:\n",
      "{'max_depth': 3, 'n_estimators': 200}\n",
      "\n",
      "====================== result for random seed: 36 ======================\n",
      "Best Linear Regression RMSE: 54307.105684363756\n",
      "Best Ridge Regression RMSE: 59157.87876489145\n",
      "Best Lasso Regression RMSE: 59160.40499936362\n",
      "Best Decision Tree Regressor RMSE: 50310.62793310575\n",
      "Best Random Forest Regressor RMSE: 48789.24544557307\n",
      "Best Gradient Boosting Regressor RMSE: 48284.318377691896\n",
      "Best AdaBoost Regressor RMSE: 51777.344408126904\n",
      "Best XGBoost Regressor RMSE: 48227.66022110023\n",
      "Best LightGBM Regressor RMSE: 48211.21730482715\n",
      "Best CatBoost Regressor RMSE: 48110.749844250255\n",
      "Best ElasticNet Regression RMSE: 59144.25923631862\n",
      "Best K-Nearest Neighbors RMSE: 51589.27557951973\n",
      "Best Support Vector Regressor RMSE: 59734.34673667276\n",
      "Best Bayesian Ridge Regression RMSE: 59161.4267467478\n",
      "Best Model: CatBoost Regressor (RMSE: 48110.749844250255)\n",
      "Best Parameters for Best Model:\n",
      "{'depth': 4, 'iterations': 200}\n",
      "\n",
      "====================== result for random seed: 37 ======================\n",
      "Best Linear Regression RMSE: 53635.80031787128\n",
      "Best Ridge Regression RMSE: 58715.29504069385\n",
      "Best Lasso Regression RMSE: 58715.02395673926\n",
      "Best Decision Tree Regressor RMSE: 50180.82599492498\n",
      "Best Random Forest Regressor RMSE: 48407.588969878336\n",
      "Best Gradient Boosting Regressor RMSE: 48070.476308055746\n",
      "Best AdaBoost Regressor RMSE: 50931.18521184479\n",
      "Best XGBoost Regressor RMSE: 48055.682871339115\n",
      "Best LightGBM Regressor RMSE: 47859.99088111308\n",
      "Best CatBoost Regressor RMSE: 48075.75845224365\n",
      "Best ElasticNet Regression RMSE: 58709.55879088254\n",
      "Best K-Nearest Neighbors RMSE: 50474.91738268377\n",
      "Best Support Vector Regressor RMSE: 59337.36552704619\n",
      "Best Bayesian Ridge Regression RMSE: 58719.0290144866\n",
      "Best Model: LightGBM Regressor (RMSE: 47859.99088111308)\n",
      "Best Parameters for Best Model:\n",
      "{'max_depth': 3, 'n_estimators': 200}\n",
      "\n",
      "====================== result for random seed: 38 ======================\n",
      "Best Linear Regression RMSE: 55985.43372157997\n",
      "Best Ridge Regression RMSE: 58875.234772533186\n",
      "Best Lasso Regression RMSE: 58876.46713015161\n",
      "Best Decision Tree Regressor RMSE: 51719.08869774761\n",
      "Best Random Forest Regressor RMSE: 49184.248564494075\n",
      "Best Gradient Boosting Regressor RMSE: 48570.18467345466\n",
      "Best AdaBoost Regressor RMSE: 52284.048811114524\n",
      "Best XGBoost Regressor RMSE: 48474.61042478757\n",
      "Best LightGBM Regressor RMSE: 48301.944874878915\n",
      "Best CatBoost Regressor RMSE: 48594.33471382926\n",
      "Best ElasticNet Regression RMSE: 58857.28808370468\n",
      "Best K-Nearest Neighbors RMSE: 51346.50019696815\n",
      "Best Support Vector Regressor RMSE: 59354.604480918024\n",
      "Best Bayesian Ridge Regression RMSE: 58866.95868484895\n",
      "Best Model: LightGBM Regressor (RMSE: 48301.944874878915)\n",
      "Best Parameters for Best Model:\n",
      "{'max_depth': 3, 'n_estimators': 200}\n",
      "\n",
      "====================== result for random seed: 39 ======================\n",
      "Best Linear Regression RMSE: 54609.3675637031\n",
      "Best Ridge Regression RMSE: 59191.66445325857\n",
      "Best Lasso Regression RMSE: 59194.11564130893\n",
      "Best Decision Tree Regressor RMSE: 51686.219752444114\n",
      "Best Random Forest Regressor RMSE: 49001.13227573468\n",
      "Best Gradient Boosting Regressor RMSE: 48193.78910264802\n",
      "Best AdaBoost Regressor RMSE: 52458.30113373231\n",
      "Best XGBoost Regressor RMSE: 48070.33602951195\n",
      "Best LightGBM Regressor RMSE: 48236.08142359414\n",
      "Best CatBoost Regressor RMSE: 48331.846894937895\n",
      "Best ElasticNet Regression RMSE: 59176.50546276347\n",
      "Best K-Nearest Neighbors RMSE: 51413.15848852919\n",
      "Best Support Vector Regressor RMSE: 59785.08819007886\n",
      "Best Bayesian Ridge Regression RMSE: 59182.20852636061\n",
      "Best Model: XGBoost Regressor (RMSE: 48070.33602951195)\n",
      "Best Parameters for Best Model:\n",
      "{'max_depth': 4, 'n_estimators': 50}\n",
      "\n",
      "====================== result for random seed: 40 ======================\n",
      "Best Linear Regression RMSE: 54161.26174940331\n",
      "Best Ridge Regression RMSE: 58714.5377550216\n",
      "Best Lasso Regression RMSE: 58717.74372991657\n",
      "Best Decision Tree Regressor RMSE: 51314.57367495161\n",
      "Best Random Forest Regressor RMSE: 48653.744311687275\n",
      "Best Gradient Boosting Regressor RMSE: 48155.057306689756\n",
      "Best AdaBoost Regressor RMSE: 52059.076841278904\n",
      "Best XGBoost Regressor RMSE: 48175.852700741176\n",
      "Best LightGBM Regressor RMSE: 48055.45161977328\n",
      "Best CatBoost Regressor RMSE: 48093.11089797625\n",
      "Best ElasticNet Regression RMSE: 58690.11122623422\n",
      "Best K-Nearest Neighbors RMSE: 52069.866051464865\n",
      "Best Support Vector Regressor RMSE: 59307.39364824305\n",
      "Best Bayesian Ridge Regression RMSE: 58699.084856184236\n",
      "Best Model: LightGBM Regressor (RMSE: 48055.45161977328)\n",
      "Best Parameters for Best Model:\n",
      "{'max_depth': 5, 'n_estimators': 100}\n",
      "\n",
      "====================== result for random seed: 41 ======================\n",
      "Best Linear Regression RMSE: 53891.95270456441\n",
      "Best Ridge Regression RMSE: 59363.68166560017\n",
      "Best Lasso Regression RMSE: 59363.93162231587\n",
      "Best Decision Tree Regressor RMSE: 51489.64952746168\n",
      "Best Random Forest Regressor RMSE: 49357.830878907014\n",
      "Best Gradient Boosting Regressor RMSE: 48804.745273780354\n",
      "Best AdaBoost Regressor RMSE: 52316.38829608981\n",
      "Best XGBoost Regressor RMSE: 48610.75949977545\n",
      "Best LightGBM Regressor RMSE: 48622.32456686909\n",
      "Best CatBoost Regressor RMSE: 48600.22041299858\n",
      "Best ElasticNet Regression RMSE: 59345.61692824514\n",
      "Best K-Nearest Neighbors RMSE: 51307.077180909946\n",
      "Best Support Vector Regressor RMSE: 59958.912064034674\n",
      "Best Bayesian Ridge Regression RMSE: 59350.474785441394\n",
      "Best Model: CatBoost Regressor (RMSE: 48600.22041299858)\n",
      "Best Parameters for Best Model:\n",
      "{'depth': 4, 'iterations': 200}\n",
      "\n",
      "====================== result for random seed: 42 ======================\n",
      "Best Linear Regression RMSE: 54584.025035488965\n",
      "Best Ridge Regression RMSE: 59093.68690244016\n",
      "Best Lasso Regression RMSE: 59095.61384401957\n",
      "Best Decision Tree Regressor RMSE: 52118.003675810454\n",
      "Best Random Forest Regressor RMSE: 49301.87647519873\n",
      "Best Gradient Boosting Regressor RMSE: 48592.977887034554\n",
      "Best AdaBoost Regressor RMSE: 52293.73877113562\n",
      "Best XGBoost Regressor RMSE: 48513.28148466242\n",
      "Best LightGBM Regressor RMSE: 48527.66843789208\n",
      "Best CatBoost Regressor RMSE: 48677.040625994734\n",
      "Best ElasticNet Regression RMSE: 59066.26523959348\n",
      "Best K-Nearest Neighbors RMSE: 52016.288232756844\n",
      "Best Support Vector Regressor RMSE: 59529.272057992865\n",
      "Best Bayesian Ridge Regression RMSE: 59078.51673238577\n",
      "Best Model: XGBoost Regressor (RMSE: 48513.28148466242)\n",
      "Best Parameters for Best Model:\n",
      "{'max_depth': 3, 'n_estimators': 100}\n",
      "\n",
      "====================== result for random seed: 43 ======================\n",
      "Best Linear Regression RMSE: 53441.48197448015\n",
      "Best Ridge Regression RMSE: 58267.723400823576\n",
      "Best Lasso Regression RMSE: 58269.16337737457\n",
      "Best Decision Tree Regressor RMSE: 50217.910083342664\n",
      "Best Random Forest Regressor RMSE: 48037.10802594983\n",
      "Best Gradient Boosting Regressor RMSE: 47750.41503026873\n",
      "Best AdaBoost Regressor RMSE: 50794.45992947297\n",
      "Best XGBoost Regressor RMSE: 47694.28388060173\n",
      "Best LightGBM Regressor RMSE: 47752.26668672961\n",
      "Best CatBoost Regressor RMSE: 47662.48252193253\n",
      "Best ElasticNet Regression RMSE: 58264.56668349633\n",
      "Best K-Nearest Neighbors RMSE: 50645.28468073744\n",
      "Best Support Vector Regressor RMSE: 58955.63354731807\n",
      "Best Bayesian Ridge Regression RMSE: 58273.535392692764\n",
      "Best Model: CatBoost Regressor (RMSE: 47662.48252193253)\n",
      "Best Parameters for Best Model:\n",
      "{'depth': 4, 'iterations': 200}\n",
      "\n",
      "====================== result for random seed: 44 ======================\n",
      "Best Linear Regression RMSE: 52022.20339664521\n",
      "Best Ridge Regression RMSE: 58912.66048206403\n",
      "Best Lasso Regression RMSE: 58914.388201501446\n",
      "Best Decision Tree Regressor RMSE: 51106.83698909082\n",
      "Best Random Forest Regressor RMSE: 48673.6193579664\n",
      "Best Gradient Boosting Regressor RMSE: 48056.29287249532\n",
      "Best AdaBoost Regressor RMSE: 51993.03172742181\n",
      "Best XGBoost Regressor RMSE: 47874.88005345683\n",
      "Best LightGBM Regressor RMSE: 48019.778125266814\n",
      "Best CatBoost Regressor RMSE: 48201.29681315691\n",
      "Best ElasticNet Regression RMSE: 58908.04564371476\n",
      "Best K-Nearest Neighbors RMSE: 52552.528735480206\n",
      "Best Support Vector Regressor RMSE: 59578.82990581189\n",
      "Best Bayesian Ridge Regression RMSE: 58922.51753594108\n",
      "Best Model: XGBoost Regressor (RMSE: 47874.88005345683)\n",
      "Best Parameters for Best Model:\n",
      "{'max_depth': 4, 'n_estimators': 50}\n",
      "\n",
      "====================== result for random seed: 45 ======================\n",
      "Best Linear Regression RMSE: 55768.7198035655\n",
      "Best Ridge Regression RMSE: 58717.30950528093\n",
      "Best Lasso Regression RMSE: 58718.5612080794\n",
      "Best Decision Tree Regressor RMSE: 51475.69010573036\n",
      "Best Random Forest Regressor RMSE: 48460.39466334839\n",
      "Best Gradient Boosting Regressor RMSE: 48082.37266464691\n",
      "Best AdaBoost Regressor RMSE: 51847.52528291206\n",
      "Best XGBoost Regressor RMSE: 47963.7290049681\n",
      "Best LightGBM Regressor RMSE: 47548.918314262555\n",
      "Best CatBoost Regressor RMSE: 47938.28812730599\n",
      "Best ElasticNet Regression RMSE: 58714.653537925304\n",
      "Best K-Nearest Neighbors RMSE: 50799.942866375335\n",
      "Best Support Vector Regressor RMSE: 59418.52116636367\n",
      "Best Bayesian Ridge Regression RMSE: 58734.307497418806\n",
      "Best Model: LightGBM Regressor (RMSE: 47548.918314262555)\n",
      "Best Parameters for Best Model:\n",
      "{'max_depth': 5, 'n_estimators': 100}\n",
      "\n",
      "====================== result for random seed: 46 ======================\n",
      "Best Linear Regression RMSE: 52754.48612162831\n",
      "Best Ridge Regression RMSE: 58632.13825700749\n",
      "Best Lasso Regression RMSE: 58633.767697537915\n",
      "Best Decision Tree Regressor RMSE: 50568.27950792464\n",
      "Best Random Forest Regressor RMSE: 48499.615177855056\n",
      "Best Gradient Boosting Regressor RMSE: 47784.86846211125\n",
      "Best AdaBoost Regressor RMSE: 51858.66386833932\n",
      "Best XGBoost Regressor RMSE: 47850.28214922966\n",
      "Best LightGBM Regressor RMSE: 47697.74495917115\n",
      "Best CatBoost Regressor RMSE: 47907.41579787888\n",
      "Best ElasticNet Regression RMSE: 58623.982574347865\n",
      "Best K-Nearest Neighbors RMSE: 51039.35213121407\n",
      "Best Support Vector Regressor RMSE: 59143.265796001746\n",
      "Best Bayesian Ridge Regression RMSE: 58641.04097105358\n",
      "Best Model: LightGBM Regressor (RMSE: 47697.74495917115)\n",
      "Best Parameters for Best Model:\n",
      "{'max_depth': 4, 'n_estimators': 200}\n",
      "\n",
      "====================== result for random seed: 47 ======================\n",
      "Best Linear Regression RMSE: 52170.77723578825\n",
      "Best Ridge Regression RMSE: 58770.173589938204\n",
      "Best Lasso Regression RMSE: 58772.51535976532\n",
      "Best Decision Tree Regressor RMSE: 50840.08470004969\n",
      "Best Random Forest Regressor RMSE: 48551.89162158044\n",
      "Best Gradient Boosting Regressor RMSE: 47928.627146438375\n",
      "Best AdaBoost Regressor RMSE: 51932.569158236074\n",
      "Best XGBoost Regressor RMSE: 47879.54740053395\n",
      "Best LightGBM Regressor RMSE: 47971.46797401379\n",
      "Best CatBoost Regressor RMSE: 47686.108167522325\n",
      "Best ElasticNet Regression RMSE: 58756.04780061112\n",
      "Best K-Nearest Neighbors RMSE: 51113.31395478841\n",
      "Best Support Vector Regressor RMSE: 59221.60611992361\n",
      "Best Bayesian Ridge Regression RMSE: 58779.877249957026\n",
      "Best Model: CatBoost Regressor (RMSE: 47686.108167522325)\n",
      "Best Parameters for Best Model:\n",
      "{'depth': 6, 'iterations': 200}\n",
      "\n",
      "====================== result for random seed: 48 ======================\n",
      "Best Linear Regression RMSE: 51338.977652899004\n",
      "Best Ridge Regression RMSE: 59173.29339941223\n",
      "Best Lasso Regression RMSE: 59174.685505914225\n",
      "Best Decision Tree Regressor RMSE: 51359.21926760489\n",
      "Best Random Forest Regressor RMSE: 48723.53011510605\n",
      "Best Gradient Boosting Regressor RMSE: 48375.55885621679\n",
      "Best AdaBoost Regressor RMSE: 52404.890720397874\n",
      "Best XGBoost Regressor RMSE: 48394.198544579915\n",
      "Best LightGBM Regressor RMSE: 48085.366027278265\n",
      "Best CatBoost Regressor RMSE: 48355.524729785524\n",
      "Best ElasticNet Regression RMSE: 59154.14907577418\n",
      "Best K-Nearest Neighbors RMSE: 51140.536763169854\n",
      "Best Support Vector Regressor RMSE: 59590.561495576585\n",
      "Best Bayesian Ridge Regression RMSE: 59167.389542019475\n",
      "Best Model: LightGBM Regressor (RMSE: 48085.366027278265)\n",
      "Best Parameters for Best Model:\n",
      "{'max_depth': 5, 'n_estimators': 200}\n",
      "\n",
      "====================== result for random seed: 49 ======================\n",
      "Best Linear Regression RMSE: 52857.574871547164\n",
      "Best Ridge Regression RMSE: 58869.950434730694\n",
      "Best Lasso Regression RMSE: 58872.696605144905\n",
      "Best Decision Tree Regressor RMSE: 52383.23386927743\n",
      "Best Random Forest Regressor RMSE: 49131.81076898227\n",
      "Best Gradient Boosting Regressor RMSE: 48507.934237148096\n",
      "Best AdaBoost Regressor RMSE: 52143.208851586925\n",
      "Best XGBoost Regressor RMSE: 48312.26993774827\n",
      "Best LightGBM Regressor RMSE: 48341.87190325891\n",
      "Best CatBoost Regressor RMSE: 48506.410070473205\n",
      "Best ElasticNet Regression RMSE: 58852.87637397013\n",
      "Best K-Nearest Neighbors RMSE: 51111.6883339867\n",
      "Best Support Vector Regressor RMSE: 59387.47284362551\n",
      "Best Bayesian Ridge Regression RMSE: 58869.022566203865\n",
      "Best Model: XGBoost Regressor (RMSE: 48312.26993774827)\n",
      "Best Parameters for Best Model:\n",
      "{'max_depth': 4, 'n_estimators': 50}\n",
      "\n",
      "====================== result for random seed: 50 ======================\n",
      "Best Linear Regression RMSE: 53782.50455957191\n",
      "Best Ridge Regression RMSE: 59211.28855313064\n",
      "Best Lasso Regression RMSE: 59213.23354875501\n",
      "Best Decision Tree Regressor RMSE: 51549.404569464954\n",
      "Best Random Forest Regressor RMSE: 49194.0918115829\n",
      "Best Gradient Boosting Regressor RMSE: 48302.561339572625\n",
      "Best AdaBoost Regressor RMSE: 51494.06978292884\n",
      "Best XGBoost Regressor RMSE: 48438.129603418485\n",
      "Best LightGBM Regressor RMSE: 48209.01174315743\n",
      "Best CatBoost Regressor RMSE: 48394.81499563419\n",
      "Best ElasticNet Regression RMSE: 59194.03494253509\n",
      "Best K-Nearest Neighbors RMSE: 52259.26338161149\n",
      "Best Support Vector Regressor RMSE: 59767.107533105795\n",
      "Best Bayesian Ridge Regression RMSE: 59199.67089197941\n",
      "Best Model: LightGBM Regressor (RMSE: 48209.01174315743)\n",
      "Best Parameters for Best Model:\n",
      "{'max_depth': 3, 'n_estimators': 200}\n",
      "\n",
      "====================== result for random seed: 51 ======================\n",
      "Best Linear Regression RMSE: 51679.2967292319\n",
      "Best Ridge Regression RMSE: 59135.18679040937\n",
      "Best Lasso Regression RMSE: 59136.521955278884\n",
      "Best Decision Tree Regressor RMSE: 51986.87499354133\n",
      "Best Random Forest Regressor RMSE: 49151.46836424342\n",
      "Best Gradient Boosting Regressor RMSE: 48698.1563687094\n",
      "Best AdaBoost Regressor RMSE: 52219.09280094857\n",
      "Best XGBoost Regressor RMSE: 48663.34516175787\n",
      "Best LightGBM Regressor RMSE: 48113.10346207617\n",
      "Best CatBoost Regressor RMSE: 48716.4244597241\n",
      "Best ElasticNet Regression RMSE: 59116.867706913436\n",
      "Best K-Nearest Neighbors RMSE: 50848.7629273821\n",
      "Best Support Vector Regressor RMSE: 59703.41003478466\n",
      "Best Bayesian Ridge Regression RMSE: 59124.02822457433\n",
      "Best Model: LightGBM Regressor (RMSE: 48113.10346207617)\n",
      "Best Parameters for Best Model:\n",
      "{'max_depth': 4, 'n_estimators': 100}\n",
      "\n",
      "====================== result for random seed: 52 ======================\n",
      "Best Linear Regression RMSE: 53485.35162669429\n",
      "Best Ridge Regression RMSE: 59069.994358970725\n",
      "Best Lasso Regression RMSE: 59073.61825730923\n",
      "Best Decision Tree Regressor RMSE: 50466.09290544726\n",
      "Best Random Forest Regressor RMSE: 48472.49859349342\n",
      "Best Gradient Boosting Regressor RMSE: 48296.27940700549\n",
      "Best AdaBoost Regressor RMSE: 52106.30379129827\n",
      "Best XGBoost Regressor RMSE: 48166.46230435665\n",
      "Best LightGBM Regressor RMSE: 48026.742453374776\n",
      "Best CatBoost Regressor RMSE: 48456.305410542496\n",
      "Best ElasticNet Regression RMSE: 59046.125326575944\n",
      "Best K-Nearest Neighbors RMSE: 50599.13060370366\n",
      "Best Support Vector Regressor RMSE: 59563.10007139353\n",
      "Best Bayesian Ridge Regression RMSE: 59059.641063494215\n",
      "Best Model: LightGBM Regressor (RMSE: 48026.742453374776)\n",
      "Best Parameters for Best Model:\n",
      "{'max_depth': 5, 'n_estimators': 200}\n",
      "\n",
      "====================== result for random seed: 53 ======================\n",
      "Best Linear Regression RMSE: 54176.664040785196\n",
      "Best Ridge Regression RMSE: 58637.8667060263\n",
      "Best Lasso Regression RMSE: 58638.59228906472\n",
      "Best Decision Tree Regressor RMSE: 51985.265055672295\n",
      "Best Random Forest Regressor RMSE: 48826.727288618786\n",
      "Best Gradient Boosting Regressor RMSE: 48439.83664060443\n",
      "Best AdaBoost Regressor RMSE: 51274.890305048866\n",
      "Best XGBoost Regressor RMSE: 48400.64918232616\n",
      "Best LightGBM Regressor RMSE: 47796.882879453035\n",
      "Best CatBoost Regressor RMSE: 48442.58461516337\n",
      "Best ElasticNet Regression RMSE: 58631.08766418785\n",
      "Best K-Nearest Neighbors RMSE: 52469.30490563597\n",
      "Best Support Vector Regressor RMSE: 59331.255773604375\n",
      "Best Bayesian Ridge Regression RMSE: 58635.84945398723\n",
      "Best Model: LightGBM Regressor (RMSE: 47796.882879453035)\n",
      "Best Parameters for Best Model:\n",
      "{'max_depth': 4, 'n_estimators': 200}\n",
      "\n",
      "====================== result for random seed: 54 ======================\n",
      "Best Linear Regression RMSE: 48897.2845485819\n",
      "Best Ridge Regression RMSE: 59032.32849838438\n",
      "Best Lasso Regression RMSE: 59033.88691203306\n",
      "Best Decision Tree Regressor RMSE: 51200.21073280401\n",
      "Best Random Forest Regressor RMSE: 48927.892880200816\n",
      "Best Gradient Boosting Regressor RMSE: 48230.79411923433\n",
      "Best AdaBoost Regressor RMSE: 51996.249191041235\n",
      "Best XGBoost Regressor RMSE: 48153.90248974971\n",
      "Best LightGBM Regressor RMSE: 48185.34812235193\n",
      "Best CatBoost Regressor RMSE: 48193.36979827881\n",
      "Best ElasticNet Regression RMSE: 59025.36309380121\n",
      "Best K-Nearest Neighbors RMSE: 51566.440634315615\n",
      "Best Support Vector Regressor RMSE: 59694.241395763056\n",
      "Best Bayesian Ridge Regression RMSE: 59032.29710152406\n",
      "Best Model: XGBoost Regressor (RMSE: 48153.90248974971)\n",
      "Best Parameters for Best Model:\n",
      "{'max_depth': 4, 'n_estimators': 50}\n",
      "\n",
      "====================== result for random seed: 55 ======================\n",
      "Best Linear Regression RMSE: 48835.03886562375\n",
      "Best Ridge Regression RMSE: 59081.67527268125\n",
      "Best Lasso Regression RMSE: 59084.313332131365\n",
      "Best Decision Tree Regressor RMSE: 50716.88077724732\n",
      "Best Random Forest Regressor RMSE: 48387.868201529076\n",
      "Best Gradient Boosting Regressor RMSE: 47738.34895139697\n",
      "Best AdaBoost Regressor RMSE: 52103.70741594109\n",
      "Best XGBoost Regressor RMSE: 47714.60373073109\n",
      "Best LightGBM Regressor RMSE: 47978.709038703084\n",
      "Best CatBoost Regressor RMSE: 47692.739356451275\n",
      "Best ElasticNet Regression RMSE: 59063.352961975215\n",
      "Best K-Nearest Neighbors RMSE: 51190.52561112344\n",
      "Best Support Vector Regressor RMSE: 59600.49850965142\n",
      "Best Bayesian Ridge Regression RMSE: 59073.674388655316\n",
      "Best Model: CatBoost Regressor (RMSE: 47692.739356451275)\n",
      "Best Parameters for Best Model:\n",
      "{'depth': 8, 'iterations': 100}\n",
      "\n",
      "====================== result for random seed: 56 ======================\n",
      "Best Linear Regression RMSE: 52612.74572654039\n",
      "Best Ridge Regression RMSE: 59116.25496063763\n",
      "Best Lasso Regression RMSE: 59120.271231944585\n",
      "Best Decision Tree Regressor RMSE: 51310.304167826354\n",
      "Best Random Forest Regressor RMSE: 48799.77619385849\n",
      "Best Gradient Boosting Regressor RMSE: 48263.34245127895\n",
      "Best AdaBoost Regressor RMSE: 52288.8864472552\n",
      "Best XGBoost Regressor RMSE: 48346.53396948931\n",
      "Best LightGBM Regressor RMSE: 48319.10442230821\n",
      "Best CatBoost Regressor RMSE: 48348.37377255936\n",
      "Best ElasticNet Regression RMSE: 59091.25768695028\n",
      "Best K-Nearest Neighbors RMSE: 50949.01831791953\n",
      "Best Support Vector Regressor RMSE: 59726.29789149279\n",
      "Best Bayesian Ridge Regression RMSE: 59115.503235757176\n",
      "Best Model: Gradient Boosting Regressor (RMSE: 48263.34245127895)\n",
      "Best Parameters for Best Model:\n",
      "{'max_depth': 4, 'n_estimators': 100}\n",
      "\n",
      "====================== result for random seed: 57 ======================\n",
      "Best Linear Regression RMSE: 55212.94524014512\n",
      "Best Ridge Regression RMSE: 59108.870127161994\n",
      "Best Lasso Regression RMSE: 59109.92127636457\n",
      "Best Decision Tree Regressor RMSE: 50491.803549115364\n",
      "Best Random Forest Regressor RMSE: 48393.485548149656\n",
      "Best Gradient Boosting Regressor RMSE: 47917.099955882455\n",
      "Best AdaBoost Regressor RMSE: 51840.63512444935\n",
      "Best XGBoost Regressor RMSE: 47749.292906003924\n",
      "Best LightGBM Regressor RMSE: 47669.553837921056\n",
      "Best CatBoost Regressor RMSE: 47784.31388714448\n",
      "Best ElasticNet Regression RMSE: 59086.393670838195\n",
      "Best K-Nearest Neighbors RMSE: 50528.17934688037\n",
      "Best Support Vector Regressor RMSE: 59550.42938751674\n",
      "Best Bayesian Ridge Regression RMSE: 59102.87203845248\n",
      "Best Model: LightGBM Regressor (RMSE: 47669.553837921056)\n",
      "Best Parameters for Best Model:\n",
      "{'max_depth': 5, 'n_estimators': 100}\n",
      "\n",
      "====================== result for random seed: 58 ======================\n",
      "Best Linear Regression RMSE: 57179.55899745007\n",
      "Best Ridge Regression RMSE: 59120.04647351341\n",
      "Best Lasso Regression RMSE: 59122.06381174178\n",
      "Best Decision Tree Regressor RMSE: 51619.2163415507\n",
      "Best Random Forest Regressor RMSE: 49012.6659816846\n",
      "Best Gradient Boosting Regressor RMSE: 48899.44017876025\n",
      "Best AdaBoost Regressor RMSE: 52467.818880389364\n",
      "Best XGBoost Regressor RMSE: 48660.695116384195\n",
      "Best LightGBM Regressor RMSE: 48604.85444902033\n",
      "Best CatBoost Regressor RMSE: 48904.75782780548\n",
      "Best ElasticNet Regression RMSE: 59109.8598080069\n",
      "Best K-Nearest Neighbors RMSE: 52113.34775348985\n",
      "Best Support Vector Regressor RMSE: 59737.90457961453\n",
      "Best Bayesian Ridge Regression RMSE: 59124.52990378353\n",
      "Best Model: LightGBM Regressor (RMSE: 48604.85444902033)\n",
      "Best Parameters for Best Model:\n",
      "{'max_depth': 5, 'n_estimators': 50}\n",
      "\n",
      "====================== result for random seed: 59 ======================\n",
      "Best Linear Regression RMSE: 52516.23800546743\n",
      "Best Ridge Regression RMSE: 58169.77765578781\n",
      "Best Lasso Regression RMSE: 58172.46886202536\n",
      "Best Decision Tree Regressor RMSE: 50072.6138601062\n",
      "Best Random Forest Regressor RMSE: 47728.563506627666\n",
      "Best Gradient Boosting Regressor RMSE: 47125.37621419971\n",
      "Best AdaBoost Regressor RMSE: 50605.97411352118\n",
      "Best XGBoost Regressor RMSE: 46988.31560122788\n",
      "Best LightGBM Regressor RMSE: 47001.12760593296\n",
      "Best CatBoost Regressor RMSE: 46796.632156077234\n",
      "Best ElasticNet Regression RMSE: 58158.80492045269\n",
      "Best K-Nearest Neighbors RMSE: 50224.26749349341\n",
      "Best Support Vector Regressor RMSE: 58840.56204171894\n",
      "Best Bayesian Ridge Regression RMSE: 58166.25775275444\n",
      "Best Model: CatBoost Regressor (RMSE: 46796.632156077234)\n",
      "Best Parameters for Best Model:\n",
      "{'depth': 4, 'iterations': 200}\n",
      "\n",
      "====================== result for random seed: 60 ======================\n",
      "Best Linear Regression RMSE: 49953.21069798637\n",
      "Best Ridge Regression RMSE: 59147.150238362905\n",
      "Best Lasso Regression RMSE: 59148.69750407356\n",
      "Best Decision Tree Regressor RMSE: 50887.584246684135\n",
      "Best Random Forest Regressor RMSE: 48774.245183005274\n",
      "Best Gradient Boosting Regressor RMSE: 48316.05026488582\n",
      "Best AdaBoost Regressor RMSE: 52108.30343678713\n",
      "Best XGBoost Regressor RMSE: 48319.732820484656\n",
      "Best LightGBM Regressor RMSE: 48010.88930701877\n",
      "Best CatBoost Regressor RMSE: 48202.93706819911\n",
      "Best ElasticNet Regression RMSE: 59139.613876712116\n",
      "Best K-Nearest Neighbors RMSE: 50944.6656653084\n",
      "Best Support Vector Regressor RMSE: 59676.30121810154\n",
      "Best Bayesian Ridge Regression RMSE: 59152.17936440638\n",
      "Best Model: LightGBM Regressor (RMSE: 48010.88930701877)\n",
      "Best Parameters for Best Model:\n",
      "{'max_depth': 3, 'n_estimators': 200}\n",
      "\n",
      "====================== result for random seed: 61 ======================\n",
      "Best Linear Regression RMSE: 55419.516267448555\n",
      "Best Ridge Regression RMSE: 58714.10224785832\n",
      "Best Lasso Regression RMSE: 58715.134364839534\n",
      "Best Decision Tree Regressor RMSE: 51222.31910156728\n",
      "Best Random Forest Regressor RMSE: 48419.30618150161\n",
      "Best Gradient Boosting Regressor RMSE: 47617.677474163225\n",
      "Best AdaBoost Regressor RMSE: 51873.63874455231\n",
      "Best XGBoost Regressor RMSE: 47298.98817541279\n",
      "Best LightGBM Regressor RMSE: 47614.80616141208\n",
      "Best CatBoost Regressor RMSE: 47554.47092564178\n",
      "Best ElasticNet Regression RMSE: 58712.02113009818\n",
      "Best K-Nearest Neighbors RMSE: 50342.584876099674\n",
      "Best Support Vector Regressor RMSE: 59391.492087993145\n",
      "Best Bayesian Ridge Regression RMSE: 58723.71531908727\n",
      "Best Model: XGBoost Regressor (RMSE: 47298.98817541279)\n",
      "Best Parameters for Best Model:\n",
      "{'max_depth': 3, 'n_estimators': 100}\n",
      "\n",
      "====================== result for random seed: 62 ======================\n",
      "Best Linear Regression RMSE: 51620.821396065854\n",
      "Best Ridge Regression RMSE: 59184.56249992328\n",
      "Best Lasso Regression RMSE: 59186.57412849855\n",
      "Best Decision Tree Regressor RMSE: 50892.01542487607\n",
      "Best Random Forest Regressor RMSE: 48859.94419541373\n",
      "Best Gradient Boosting Regressor RMSE: 48180.346957573485\n",
      "Best AdaBoost Regressor RMSE: 51975.71287463669\n",
      "Best XGBoost Regressor RMSE: 48371.786352656476\n",
      "Best LightGBM Regressor RMSE: 48002.02589379441\n",
      "Best CatBoost Regressor RMSE: 48092.07655760898\n",
      "Best ElasticNet Regression RMSE: 59174.13760475627\n",
      "Best K-Nearest Neighbors RMSE: 51447.3024196795\n",
      "Best Support Vector Regressor RMSE: 59785.63880608881\n",
      "Best Bayesian Ridge Regression RMSE: 59181.23549542669\n",
      "Best Model: LightGBM Regressor (RMSE: 48002.02589379441)\n",
      "Best Parameters for Best Model:\n",
      "{'max_depth': 3, 'n_estimators': 200}\n",
      "\n",
      "====================== result for random seed: 63 ======================\n",
      "Best Linear Regression RMSE: 53712.13371487374\n",
      "Best Ridge Regression RMSE: 59438.55780646916\n",
      "Best Lasso Regression RMSE: 59440.21673286412\n",
      "Best Decision Tree Regressor RMSE: 51828.32569313832\n",
      "Best Random Forest Regressor RMSE: 49215.54868276851\n",
      "Best Gradient Boosting Regressor RMSE: 48517.49585104685\n",
      "Best AdaBoost Regressor RMSE: 52404.63647458827\n",
      "Best XGBoost Regressor RMSE: 48626.070452361484\n",
      "Best LightGBM Regressor RMSE: 48211.839002274406\n",
      "Best CatBoost Regressor RMSE: 48524.93297187955\n",
      "Best ElasticNet Regression RMSE: 59406.294070085205\n",
      "Best K-Nearest Neighbors RMSE: 51482.31080982526\n",
      "Best Support Vector Regressor RMSE: 60020.72873374226\n",
      "Best Bayesian Ridge Regression RMSE: 59420.91301925026\n",
      "Best Model: LightGBM Regressor (RMSE: 48211.839002274406)\n",
      "Best Parameters for Best Model:\n",
      "{'max_depth': 4, 'n_estimators': 200}\n",
      "\n",
      "====================== result for random seed: 64 ======================\n",
      "Best Linear Regression RMSE: 51950.63240128262\n",
      "Best Ridge Regression RMSE: 58792.400829730665\n",
      "Best Lasso Regression RMSE: 58796.081301397084\n",
      "Best Decision Tree Regressor RMSE: 51620.11658921027\n",
      "Best Random Forest Regressor RMSE: 48886.238835070224\n",
      "Best Gradient Boosting Regressor RMSE: 48381.22541635051\n",
      "Best AdaBoost Regressor RMSE: 51973.01233093433\n",
      "Best XGBoost Regressor RMSE: 48381.090304647405\n",
      "Best LightGBM Regressor RMSE: 48099.693730590916\n",
      "Best CatBoost Regressor RMSE: 48348.15450141308\n",
      "Best ElasticNet Regression RMSE: 58768.42697195921\n",
      "Best K-Nearest Neighbors RMSE: 50500.898292207705\n",
      "Best Support Vector Regressor RMSE: 59402.7771837559\n",
      "Best Bayesian Ridge Regression RMSE: 58784.7394348693\n",
      "Best Model: LightGBM Regressor (RMSE: 48099.693730590916)\n",
      "Best Parameters for Best Model:\n",
      "{'max_depth': 4, 'n_estimators': 200}\n",
      "\n",
      "====================== result for random seed: 65 ======================\n",
      "Best Linear Regression RMSE: 55351.099394817094\n",
      "Best Ridge Regression RMSE: 58530.92521125289\n",
      "Best Lasso Regression RMSE: 58533.14580424832\n",
      "Best Decision Tree Regressor RMSE: 50131.89127964108\n",
      "Best Random Forest Regressor RMSE: 48187.29029892184\n",
      "Best Gradient Boosting Regressor RMSE: 47852.311820620336\n",
      "Best AdaBoost Regressor RMSE: 51865.10285823063\n",
      "Best XGBoost Regressor RMSE: 47864.8833927561\n",
      "Best LightGBM Regressor RMSE: 47724.648341542605\n",
      "Best CatBoost Regressor RMSE: 47908.340421770416\n",
      "Best ElasticNet Regression RMSE: 58509.01641601493\n",
      "Best K-Nearest Neighbors RMSE: 51282.63352572206\n",
      "Best Support Vector Regressor RMSE: 59077.13476757497\n",
      "Best Bayesian Ridge Regression RMSE: 58518.3456405819\n",
      "Best Model: LightGBM Regressor (RMSE: 47724.648341542605)\n",
      "Best Parameters for Best Model:\n",
      "{'max_depth': 4, 'n_estimators': 100}\n",
      "\n",
      "====================== result for random seed: 66 ======================\n",
      "Best Linear Regression RMSE: 54475.65677334737\n",
      "Best Ridge Regression RMSE: 58628.580160834295\n",
      "Best Lasso Regression RMSE: 58631.000276601546\n",
      "Best Decision Tree Regressor RMSE: 49585.09068056742\n",
      "Best Random Forest Regressor RMSE: 48041.54933914374\n",
      "Best Gradient Boosting Regressor RMSE: 47692.600716330606\n",
      "Best AdaBoost Regressor RMSE: 51218.56924091177\n",
      "Best XGBoost Regressor RMSE: 47488.2978529155\n",
      "Best LightGBM Regressor RMSE: 47587.09964235801\n",
      "Best CatBoost Regressor RMSE: 47396.50167216223\n",
      "Best ElasticNet Regression RMSE: 58618.810088553895\n",
      "Best K-Nearest Neighbors RMSE: 50924.67485007684\n",
      "Best Support Vector Regressor RMSE: 59287.090591976186\n",
      "Best Bayesian Ridge Regression RMSE: 58633.8437735576\n",
      "Best Model: CatBoost Regressor (RMSE: 47396.50167216223)\n",
      "Best Parameters for Best Model:\n",
      "{'depth': 4, 'iterations': 200}\n",
      "\n",
      "====================== result for random seed: 67 ======================\n",
      "Best Linear Regression RMSE: 54516.05086539494\n",
      "Best Ridge Regression RMSE: 59239.79180056463\n",
      "Best Lasso Regression RMSE: 59241.72712584813\n",
      "Best Decision Tree Regressor RMSE: 51830.17292013982\n",
      "Best Random Forest Regressor RMSE: 49624.79153274921\n",
      "Best Gradient Boosting Regressor RMSE: 48619.520508767775\n",
      "Best AdaBoost Regressor RMSE: 52482.07758860003\n",
      "Best XGBoost Regressor RMSE: 48700.79446340678\n",
      "Best LightGBM Regressor RMSE: 48359.14804634495\n",
      "Best CatBoost Regressor RMSE: 48518.96473954659\n",
      "Best ElasticNet Regression RMSE: 59225.36485010725\n",
      "Best K-Nearest Neighbors RMSE: 51222.11077206586\n",
      "Best Support Vector Regressor RMSE: 59704.68748675877\n",
      "Best Bayesian Ridge Regression RMSE: 59254.503813462135\n",
      "Best Model: LightGBM Regressor (RMSE: 48359.14804634495)\n",
      "Best Parameters for Best Model:\n",
      "{'max_depth': 4, 'n_estimators': 100}\n",
      "\n",
      "====================== result for random seed: 68 ======================\n",
      "Best Linear Regression RMSE: 53475.05183165257\n",
      "Best Ridge Regression RMSE: 58820.5708219269\n",
      "Best Lasso Regression RMSE: 58821.914527996094\n",
      "Best Decision Tree Regressor RMSE: 51759.67865637892\n",
      "Best Random Forest Regressor RMSE: 49119.69872498585\n",
      "Best Gradient Boosting Regressor RMSE: 48432.830234960216\n",
      "Best AdaBoost Regressor RMSE: 52337.93419779304\n",
      "Best XGBoost Regressor RMSE: 48601.37485692825\n",
      "Best LightGBM Regressor RMSE: 48445.99973699127\n",
      "Best CatBoost Regressor RMSE: 48510.05925442507\n",
      "Best ElasticNet Regression RMSE: 58815.3386669387\n",
      "Best K-Nearest Neighbors RMSE: 51119.811931727825\n",
      "Best Support Vector Regressor RMSE: 59467.33736557995\n",
      "Best Bayesian Ridge Regression RMSE: 58829.99435406708\n",
      "Best Model: Gradient Boosting Regressor (RMSE: 48432.830234960216)\n",
      "Best Parameters for Best Model:\n",
      "{'max_depth': 3, 'n_estimators': 200}\n",
      "\n",
      "====================== result for random seed: 69 ======================\n",
      "Best Linear Regression RMSE: 51539.22303728925\n",
      "Best Ridge Regression RMSE: 58713.5954052043\n",
      "Best Lasso Regression RMSE: 58715.973782013614\n",
      "Best Decision Tree Regressor RMSE: 51127.69870686773\n",
      "Best Random Forest Regressor RMSE: 48771.39133118663\n",
      "Best Gradient Boosting Regressor RMSE: 48191.73343487871\n",
      "Best AdaBoost Regressor RMSE: 51594.55795807405\n",
      "Best XGBoost Regressor RMSE: 48233.668503472654\n",
      "Best LightGBM Regressor RMSE: 47968.235604653055\n",
      "Best CatBoost Regressor RMSE: 48067.35975581484\n",
      "Best ElasticNet Regression RMSE: 58703.45150581644\n",
      "Best K-Nearest Neighbors RMSE: 51292.83487222566\n",
      "Best Support Vector Regressor RMSE: 59394.76365606396\n",
      "Best Bayesian Ridge Regression RMSE: 58710.55475646566\n",
      "Best Model: LightGBM Regressor (RMSE: 47968.235604653055)\n",
      "Best Parameters for Best Model:\n",
      "{'max_depth': 5, 'n_estimators': 100}\n",
      "\n",
      "====================== result for random seed: 70 ======================\n",
      "Best Linear Regression RMSE: 55628.79634894014\n",
      "Best Ridge Regression RMSE: 59363.89030872836\n",
      "Best Lasso Regression RMSE: 59368.85515918791\n",
      "Best Decision Tree Regressor RMSE: 51185.533358315806\n",
      "Best Random Forest Regressor RMSE: 49074.67893246915\n",
      "Best Gradient Boosting Regressor RMSE: 48712.51514657916\n",
      "Best AdaBoost Regressor RMSE: 52162.377454672365\n",
      "Best XGBoost Regressor RMSE: 48639.04607394261\n",
      "Best LightGBM Regressor RMSE: 48351.04917208038\n",
      "Best CatBoost Regressor RMSE: 48585.39994523202\n",
      "Best ElasticNet Regression RMSE: 59326.559115721626\n",
      "Best K-Nearest Neighbors RMSE: 51820.93640652363\n",
      "Best Support Vector Regressor RMSE: 59852.422016599165\n",
      "Best Bayesian Ridge Regression RMSE: 59341.55220844796\n",
      "Best Model: LightGBM Regressor (RMSE: 48351.04917208038)\n",
      "Best Parameters for Best Model:\n",
      "{'max_depth': 3, 'n_estimators': 200}\n",
      "\n",
      "====================== result for random seed: 71 ======================\n",
      "Best Linear Regression RMSE: 53998.272519616476\n",
      "Best Ridge Regression RMSE: 58764.43749126994\n",
      "Best Lasso Regression RMSE: 58765.91302716612\n",
      "Best Decision Tree Regressor RMSE: 51916.75323316734\n",
      "Best Random Forest Regressor RMSE: 48242.44139758421\n",
      "Best Gradient Boosting Regressor RMSE: 47762.2399299008\n",
      "Best AdaBoost Regressor RMSE: 51676.676765396485\n",
      "Best XGBoost Regressor RMSE: 47360.466514165775\n",
      "Best LightGBM Regressor RMSE: 47556.77675365265\n",
      "Best CatBoost Regressor RMSE: 47382.59913785291\n",
      "Best ElasticNet Regression RMSE: 58760.30726730148\n",
      "Best K-Nearest Neighbors RMSE: 51268.50317116958\n",
      "Best Support Vector Regressor RMSE: 59376.97694860021\n",
      "Best Bayesian Ridge Regression RMSE: 58769.04247129239\n",
      "Best Model: XGBoost Regressor (RMSE: 47360.466514165775)\n",
      "Best Parameters for Best Model:\n",
      "{'max_depth': 3, 'n_estimators': 50}\n",
      "\n",
      "====================== result for random seed: 72 ======================\n",
      "Best Linear Regression RMSE: 56490.93751980651\n",
      "Best Ridge Regression RMSE: 59583.46854746636\n",
      "Best Lasso Regression RMSE: 59584.90991827602\n",
      "Best Decision Tree Regressor RMSE: 51599.47348593697\n",
      "Best Random Forest Regressor RMSE: 49278.00751851056\n",
      "Best Gradient Boosting Regressor RMSE: 48859.705009286736\n",
      "Best AdaBoost Regressor RMSE: 52630.936590790945\n",
      "Best XGBoost Regressor RMSE: 48739.51392503078\n",
      "Best LightGBM Regressor RMSE: 48610.63124508471\n",
      "Best CatBoost Regressor RMSE: 48698.451558013665\n",
      "Best ElasticNet Regression RMSE: 59576.91527879384\n",
      "Best K-Nearest Neighbors RMSE: 51880.00634493056\n",
      "Best Support Vector Regressor RMSE: 60200.533758346595\n",
      "Best Bayesian Ridge Regression RMSE: 59585.23302868121\n",
      "Best Model: LightGBM Regressor (RMSE: 48610.63124508471)\n",
      "Best Parameters for Best Model:\n",
      "{'max_depth': 5, 'n_estimators': 100}\n",
      "\n",
      "====================== result for random seed: 73 ======================\n",
      "Best Linear Regression RMSE: 52431.83781123281\n",
      "Best Ridge Regression RMSE: 59608.76813968677\n",
      "Best Lasso Regression RMSE: 59612.03706529672\n",
      "Best Decision Tree Regressor RMSE: 52336.924173042054\n",
      "Best Random Forest Regressor RMSE: 49405.22354565722\n",
      "Best Gradient Boosting Regressor RMSE: 48985.97813500943\n",
      "Best AdaBoost Regressor RMSE: 52694.1976997482\n",
      "Best XGBoost Regressor RMSE: 48742.78606383233\n",
      "Best LightGBM Regressor RMSE: 48591.984270059416\n",
      "Best CatBoost Regressor RMSE: 48830.822867410505\n",
      "Best ElasticNet Regression RMSE: 59588.98929156034\n",
      "Best K-Nearest Neighbors RMSE: 51667.803383450075\n",
      "Best Support Vector Regressor RMSE: 60106.38843893881\n",
      "Best Bayesian Ridge Regression RMSE: 59594.92874830129\n",
      "Best Model: LightGBM Regressor (RMSE: 48591.984270059416)\n",
      "Best Parameters for Best Model:\n",
      "{'max_depth': 4, 'n_estimators': 200}\n",
      "\n",
      "====================== result for random seed: 74 ======================\n",
      "Best Linear Regression RMSE: 53861.07484758756\n",
      "Best Ridge Regression RMSE: 58317.160408088086\n",
      "Best Lasso Regression RMSE: 58321.769773359425\n",
      "Best Decision Tree Regressor RMSE: 50917.0770012045\n",
      "Best Random Forest Regressor RMSE: 48118.29146513102\n",
      "Best Gradient Boosting Regressor RMSE: 47394.33158444434\n",
      "Best AdaBoost Regressor RMSE: 50515.72006357357\n",
      "Best XGBoost Regressor RMSE: 47377.02989974111\n",
      "Best LightGBM Regressor RMSE: 47023.245313743915\n",
      "Best CatBoost Regressor RMSE: 47195.239950868425\n",
      "Best ElasticNet Regression RMSE: 58271.948963083196\n",
      "Best K-Nearest Neighbors RMSE: 50445.394520616544\n",
      "Best Support Vector Regressor RMSE: 58790.27465234888\n",
      "Best Bayesian Ridge Regression RMSE: 58284.77875336467\n",
      "Best Model: LightGBM Regressor (RMSE: 47023.245313743915)\n",
      "Best Parameters for Best Model:\n",
      "{'max_depth': 3, 'n_estimators': 200}\n",
      "\n",
      "====================== result for random seed: 75 ======================\n",
      "Best Linear Regression RMSE: 54272.67086689074\n",
      "Best Ridge Regression RMSE: 59319.32471922453\n",
      "Best Lasso Regression RMSE: 59321.01990694459\n",
      "Best Decision Tree Regressor RMSE: 52125.89420952784\n",
      "Best Random Forest Regressor RMSE: 49390.03356927141\n",
      "Best Gradient Boosting Regressor RMSE: 48916.628132255115\n",
      "Best AdaBoost Regressor RMSE: 52560.87572465066\n",
      "Best XGBoost Regressor RMSE: 48882.40827593098\n",
      "Best LightGBM Regressor RMSE: 48860.933415624575\n",
      "Best CatBoost Regressor RMSE: 48891.91896402368\n",
      "Best ElasticNet Regression RMSE: 59297.12795399999\n",
      "Best K-Nearest Neighbors RMSE: 51820.937123672265\n",
      "Best Support Vector Regressor RMSE: 59962.38116045267\n",
      "Best Bayesian Ridge Regression RMSE: 59307.60537877367\n",
      "Best Model: LightGBM Regressor (RMSE: 48860.933415624575)\n",
      "Best Parameters for Best Model:\n",
      "{'max_depth': 4, 'n_estimators': 100}\n",
      "\n",
      "====================== result for random seed: 76 ======================\n",
      "Best Linear Regression RMSE: 52029.01266393667\n",
      "Best Ridge Regression RMSE: 58805.47930468259\n",
      "Best Lasso Regression RMSE: 58807.848288638066\n",
      "Best Decision Tree Regressor RMSE: 52665.112936937534\n",
      "Best Random Forest Regressor RMSE: 49012.96687740122\n",
      "Best Gradient Boosting Regressor RMSE: 48164.13448548327\n",
      "Best AdaBoost Regressor RMSE: 52425.862659222694\n",
      "Best XGBoost Regressor RMSE: 47958.694590886\n",
      "Best LightGBM Regressor RMSE: 48050.18850869093\n",
      "Best CatBoost Regressor RMSE: 48129.070072750714\n",
      "Best ElasticNet Regression RMSE: 58796.22188242066\n",
      "Best K-Nearest Neighbors RMSE: 51049.37974465916\n",
      "Best Support Vector Regressor RMSE: 59369.332265690246\n",
      "Best Bayesian Ridge Regression RMSE: 58807.03376753045\n",
      "Best Model: XGBoost Regressor (RMSE: 47958.694590886)\n",
      "Best Parameters for Best Model:\n",
      "{'max_depth': 4, 'n_estimators': 50}\n",
      "\n",
      "====================== result for random seed: 77 ======================\n",
      "Best Linear Regression RMSE: 52751.25382677482\n",
      "Best Ridge Regression RMSE: 58256.81796530571\n",
      "Best Lasso Regression RMSE: 58260.593900573054\n",
      "Best Decision Tree Regressor RMSE: 50474.77219754824\n",
      "Best Random Forest Regressor RMSE: 47752.13264360773\n",
      "Best Gradient Boosting Regressor RMSE: 46882.43801531235\n",
      "Best AdaBoost Regressor RMSE: 50767.73070325441\n",
      "Best XGBoost Regressor RMSE: 46730.467969439305\n",
      "Best LightGBM Regressor RMSE: 46890.808343932236\n",
      "Best CatBoost Regressor RMSE: 46897.30997170278\n",
      "Best ElasticNet Regression RMSE: 58236.42192618255\n",
      "Best K-Nearest Neighbors RMSE: 50241.81114217459\n",
      "Best Support Vector Regressor RMSE: 58851.12964344827\n",
      "Best Bayesian Ridge Regression RMSE: 58250.26806352604\n",
      "Best Model: XGBoost Regressor (RMSE: 46730.467969439305)\n",
      "Best Parameters for Best Model:\n",
      "{'max_depth': 3, 'n_estimators': 100}\n",
      "\n",
      "====================== result for random seed: 78 ======================\n",
      "Best Linear Regression RMSE: 52060.66724589078\n",
      "Best Ridge Regression RMSE: 58970.85182800231\n",
      "Best Lasso Regression RMSE: 58973.56176213274\n",
      "Best Decision Tree Regressor RMSE: 51222.81140752945\n",
      "Best Random Forest Regressor RMSE: 48875.03850340955\n",
      "Best Gradient Boosting Regressor RMSE: 48346.17369569459\n",
      "Best AdaBoost Regressor RMSE: 51936.79130492509\n",
      "Best XGBoost Regressor RMSE: 48051.16648752297\n",
      "Best LightGBM Regressor RMSE: 48397.30886299663\n",
      "Best CatBoost Regressor RMSE: 48249.578774700254\n",
      "Best ElasticNet Regression RMSE: 58956.49340366822\n",
      "Best K-Nearest Neighbors RMSE: 51051.50857074692\n",
      "Best Support Vector Regressor RMSE: 59547.00512735405\n",
      "Best Bayesian Ridge Regression RMSE: 58965.43546229307\n",
      "Best Model: XGBoost Regressor (RMSE: 48051.16648752297)\n",
      "Best Parameters for Best Model:\n",
      "{'max_depth': 4, 'n_estimators': 50}\n",
      "\n",
      "====================== result for random seed: 79 ======================\n",
      "Best Linear Regression RMSE: 53647.12076675373\n",
      "Best Ridge Regression RMSE: 58759.06350953441\n",
      "Best Lasso Regression RMSE: 58760.48351067135\n",
      "Best Decision Tree Regressor RMSE: 51929.673071300866\n",
      "Best Random Forest Regressor RMSE: 49160.61287991311\n",
      "Best Gradient Boosting Regressor RMSE: 48509.76677174527\n",
      "Best AdaBoost Regressor RMSE: 52202.04379840534\n",
      "Best XGBoost Regressor RMSE: 48448.08452752069\n",
      "Best LightGBM Regressor RMSE: 48106.71588831519\n",
      "Best CatBoost Regressor RMSE: 48411.55260584775\n",
      "Best ElasticNet Regression RMSE: 58733.823825384854\n",
      "Best K-Nearest Neighbors RMSE: 50989.33876099626\n",
      "Best Support Vector Regressor RMSE: 59381.33384940776\n",
      "Best Bayesian Ridge Regression RMSE: 58737.92527569751\n",
      "Best Model: LightGBM Regressor (RMSE: 48106.71588831519)\n",
      "Best Parameters for Best Model:\n",
      "{'max_depth': 4, 'n_estimators': 200}\n",
      "\n",
      "====================== result for random seed: 80 ======================\n",
      "Best Linear Regression RMSE: 52609.197415818235\n",
      "Best Ridge Regression RMSE: 58624.056632199776\n",
      "Best Lasso Regression RMSE: 58625.00669143917\n",
      "Best Decision Tree Regressor RMSE: 51089.669295228334\n",
      "Best Random Forest Regressor RMSE: 48506.068867905575\n",
      "Best Gradient Boosting Regressor RMSE: 47799.375926110355\n",
      "Best AdaBoost Regressor RMSE: 51888.708174876185\n",
      "Best XGBoost Regressor RMSE: 47890.02483093572\n",
      "Best LightGBM Regressor RMSE: 47922.21467988747\n",
      "Best CatBoost Regressor RMSE: 47745.23857087399\n",
      "Best ElasticNet Regression RMSE: 58621.6519046481\n",
      "Best K-Nearest Neighbors RMSE: 50703.19436973216\n",
      "Best Support Vector Regressor RMSE: 59144.440455159325\n",
      "Best Bayesian Ridge Regression RMSE: 58633.13947680216\n",
      "Best Model: CatBoost Regressor (RMSE: 47745.23857087399)\n",
      "Best Parameters for Best Model:\n",
      "{'depth': 4, 'iterations': 200}\n",
      "\n",
      "====================== result for random seed: 81 ======================\n",
      "Best Linear Regression RMSE: 55672.56867550151\n",
      "Best Ridge Regression RMSE: 59281.185663409844\n",
      "Best Lasso Regression RMSE: 59283.35043977693\n",
      "Best Decision Tree Regressor RMSE: 50862.30901033705\n",
      "Best Random Forest Regressor RMSE: 48555.959399920495\n",
      "Best Gradient Boosting Regressor RMSE: 48354.31500116758\n",
      "Best AdaBoost Regressor RMSE: 52141.865946723\n",
      "Best XGBoost Regressor RMSE: 48004.54809318726\n",
      "Best LightGBM Regressor RMSE: 48296.37219531239\n",
      "Best CatBoost Regressor RMSE: 48144.34486375687\n",
      "Best ElasticNet Regression RMSE: 59270.01620424345\n",
      "Best K-Nearest Neighbors RMSE: 50699.971141794354\n",
      "Best Support Vector Regressor RMSE: 59788.89096495846\n",
      "Best Bayesian Ridge Regression RMSE: 59279.59852793406\n",
      "Best Model: XGBoost Regressor (RMSE: 48004.54809318726)\n",
      "Best Parameters for Best Model:\n",
      "{'max_depth': 4, 'n_estimators': 50}\n",
      "\n",
      "====================== result for random seed: 82 ======================\n",
      "Best Linear Regression RMSE: 55036.14340324385\n",
      "Best Ridge Regression RMSE: 58899.50313017279\n",
      "Best Lasso Regression RMSE: 58903.36875862068\n",
      "Best Decision Tree Regressor RMSE: 50814.451934934455\n",
      "Best Random Forest Regressor RMSE: 48473.618830485895\n",
      "Best Gradient Boosting Regressor RMSE: 47891.84994624577\n",
      "Best AdaBoost Regressor RMSE: 51999.127304889655\n",
      "Best XGBoost Regressor RMSE: 48000.47484741433\n",
      "Best LightGBM Regressor RMSE: 48154.735668573725\n",
      "Best CatBoost Regressor RMSE: 47806.38422134187\n",
      "Best ElasticNet Regression RMSE: 58874.89878010593\n",
      "Best K-Nearest Neighbors RMSE: 50705.16969124542\n",
      "Best Support Vector Regressor RMSE: 59445.28535570387\n",
      "Best Bayesian Ridge Regression RMSE: 58883.675266685495\n",
      "Best Model: CatBoost Regressor (RMSE: 47806.38422134187)\n",
      "Best Parameters for Best Model:\n",
      "{'depth': 4, 'iterations': 200}\n",
      "\n",
      "====================== result for random seed: 83 ======================\n",
      "Best Linear Regression RMSE: 53591.896168934116\n",
      "Best Ridge Regression RMSE: 59289.42456910097\n",
      "Best Lasso Regression RMSE: 59293.35297160388\n",
      "Best Decision Tree Regressor RMSE: 51645.648825861885\n",
      "Best Random Forest Regressor RMSE: 49057.621698643285\n",
      "Best Gradient Boosting Regressor RMSE: 48855.23350060784\n",
      "Best AdaBoost Regressor RMSE: 52109.97602425926\n",
      "Best XGBoost Regressor RMSE: 48629.11717937473\n",
      "Best LightGBM Regressor RMSE: 48447.1154776135\n",
      "Best CatBoost Regressor RMSE: 48584.762679931\n",
      "Best ElasticNet Regression RMSE: 59247.47811822098\n",
      "Best K-Nearest Neighbors RMSE: 50967.427423261586\n",
      "Best Support Vector Regressor RMSE: 59849.2767668381\n",
      "Best Bayesian Ridge Regression RMSE: 59263.41129682056\n",
      "Best Model: LightGBM Regressor (RMSE: 48447.1154776135)\n",
      "Best Parameters for Best Model:\n",
      "{'max_depth': 4, 'n_estimators': 100}\n",
      "\n",
      "====================== result for random seed: 84 ======================\n",
      "Best Linear Regression RMSE: 50714.76080617373\n",
      "Best Ridge Regression RMSE: 58941.036950610105\n",
      "Best Lasso Regression RMSE: 58943.08004369222\n",
      "Best Decision Tree Regressor RMSE: 51263.69193532644\n",
      "Best Random Forest Regressor RMSE: 48661.4546382179\n",
      "Best Gradient Boosting Regressor RMSE: 47962.40044088834\n",
      "Best AdaBoost Regressor RMSE: 50891.71745994691\n",
      "Best XGBoost Regressor RMSE: 47896.84505261464\n",
      "Best LightGBM Regressor RMSE: 47279.501361780895\n",
      "Best CatBoost Regressor RMSE: 47844.9834293264\n",
      "Best ElasticNet Regression RMSE: 58897.01960023952\n",
      "Best K-Nearest Neighbors RMSE: 51073.21712727934\n",
      "Best Support Vector Regressor RMSE: 59354.89198812428\n",
      "Best Bayesian Ridge Regression RMSE: 58918.383321170244\n",
      "Best Model: LightGBM Regressor (RMSE: 47279.501361780895)\n",
      "Best Parameters for Best Model:\n",
      "{'max_depth': 4, 'n_estimators': 200}\n",
      "\n",
      "====================== result for random seed: 85 ======================\n",
      "Best Linear Regression RMSE: 51914.82140097319\n",
      "Best Ridge Regression RMSE: 59329.30122495267\n",
      "Best Lasso Regression RMSE: 59331.731074432006\n",
      "Best Decision Tree Regressor RMSE: 51488.857195106146\n",
      "Best Random Forest Regressor RMSE: 48884.54472182642\n",
      "Best Gradient Boosting Regressor RMSE: 48244.31714795077\n",
      "Best AdaBoost Regressor RMSE: 52282.545718474474\n",
      "Best XGBoost Regressor RMSE: 48218.00300828671\n",
      "Best LightGBM Regressor RMSE: 48031.50678022781\n",
      "Best CatBoost Regressor RMSE: 48024.77264893974\n",
      "Best ElasticNet Regression RMSE: 59313.70312554611\n",
      "Best K-Nearest Neighbors RMSE: 51757.541881083256\n",
      "Best Support Vector Regressor RMSE: 59903.38117915567\n",
      "Best Bayesian Ridge Regression RMSE: 59326.60899468437\n",
      "Best Model: CatBoost Regressor (RMSE: 48024.77264893974)\n",
      "Best Parameters for Best Model:\n",
      "{'depth': 4, 'iterations': 200}\n",
      "\n",
      "====================== result for random seed: 86 ======================\n",
      "Best Linear Regression RMSE: 53059.6701582079\n",
      "Best Ridge Regression RMSE: 58858.4047864488\n",
      "Best Lasso Regression RMSE: 58862.73574737929\n",
      "Best Decision Tree Regressor RMSE: 50722.97017178179\n",
      "Best Random Forest Regressor RMSE: 48301.28904706991\n",
      "Best Gradient Boosting Regressor RMSE: 47751.206399314506\n",
      "Best AdaBoost Regressor RMSE: 52145.38076676453\n",
      "Best XGBoost Regressor RMSE: 47868.04661694851\n",
      "Best LightGBM Regressor RMSE: 47884.47518710151\n",
      "Best CatBoost Regressor RMSE: 47949.093484019395\n",
      "Best ElasticNet Regression RMSE: 58829.62382267771\n",
      "Best K-Nearest Neighbors RMSE: 50577.72552999497\n",
      "Best Support Vector Regressor RMSE: 59371.003109429264\n",
      "Best Bayesian Ridge Regression RMSE: 58863.35423959202\n",
      "Best Model: Gradient Boosting Regressor (RMSE: 47751.206399314506)\n",
      "Best Parameters for Best Model:\n",
      "{'max_depth': 4, 'n_estimators': 200}\n",
      "\n",
      "====================== result for random seed: 87 ======================\n",
      "Best Linear Regression RMSE: 50996.61881511047\n",
      "Best Ridge Regression RMSE: 58874.48824246224\n",
      "Best Lasso Regression RMSE: 58877.76991573888\n",
      "Best Decision Tree Regressor RMSE: 51405.949206307654\n",
      "Best Random Forest Regressor RMSE: 48581.28749739358\n",
      "Best Gradient Boosting Regressor RMSE: 48094.417955172044\n",
      "Best AdaBoost Regressor RMSE: 51909.70283446091\n",
      "Best XGBoost Regressor RMSE: 47996.39940463526\n",
      "Best LightGBM Regressor RMSE: 47800.37951107857\n",
      "Best CatBoost Regressor RMSE: 47891.187275551005\n",
      "Best ElasticNet Regression RMSE: 58854.66657579361\n",
      "Best K-Nearest Neighbors RMSE: 50496.95800589131\n",
      "Best Support Vector Regressor RMSE: 59457.99281126097\n",
      "Best Bayesian Ridge Regression RMSE: 58857.77952384916\n",
      "Best Model: LightGBM Regressor (RMSE: 47800.37951107857)\n",
      "Best Parameters for Best Model:\n",
      "{'max_depth': 5, 'n_estimators': 100}\n",
      "\n",
      "====================== result for random seed: 88 ======================\n",
      "Best Linear Regression RMSE: 53752.797385046004\n",
      "Best Ridge Regression RMSE: 58522.7026520062\n",
      "Best Lasso Regression RMSE: 58524.17696127591\n",
      "Best Decision Tree Regressor RMSE: 50759.62863615199\n",
      "Best Random Forest Regressor RMSE: 48280.460216518244\n",
      "Best Gradient Boosting Regressor RMSE: 48081.21714731739\n",
      "Best AdaBoost Regressor RMSE: 51660.730179324106\n",
      "Best XGBoost Regressor RMSE: 47763.849254507615\n",
      "Best LightGBM Regressor RMSE: 47620.44922589721\n",
      "Best CatBoost Regressor RMSE: 47564.75862298158\n",
      "Best ElasticNet Regression RMSE: 58516.72332558887\n",
      "Best K-Nearest Neighbors RMSE: 50441.72996341686\n",
      "Best Support Vector Regressor RMSE: 59143.38434349884\n",
      "Best Bayesian Ridge Regression RMSE: 58530.135047965894\n",
      "Best Model: CatBoost Regressor (RMSE: 47564.75862298158)\n",
      "Best Parameters for Best Model:\n",
      "{'depth': 4, 'iterations': 200}\n",
      "\n",
      "====================== result for random seed: 89 ======================\n",
      "Best Linear Regression RMSE: 53602.15964549391\n",
      "Best Ridge Regression RMSE: 58787.577886055165\n",
      "Best Lasso Regression RMSE: 58787.92629503385\n",
      "Best Decision Tree Regressor RMSE: 51848.27562348715\n",
      "Best Random Forest Regressor RMSE: 48820.322325550136\n",
      "Best Gradient Boosting Regressor RMSE: 48573.45597873174\n",
      "Best AdaBoost Regressor RMSE: 52052.629564458715\n",
      "Best XGBoost Regressor RMSE: 48470.10036773334\n",
      "Best LightGBM Regressor RMSE: 48296.646129877154\n",
      "Best CatBoost Regressor RMSE: 48410.028514491205\n",
      "Best ElasticNet Regression RMSE: 58782.074084422726\n",
      "Best K-Nearest Neighbors RMSE: 51308.95723159396\n",
      "Best Support Vector Regressor RMSE: 59347.588678072\n",
      "Best Bayesian Ridge Regression RMSE: 58789.30073787417\n",
      "Best Model: LightGBM Regressor (RMSE: 48296.646129877154)\n",
      "Best Parameters for Best Model:\n",
      "{'max_depth': 3, 'n_estimators': 200}\n",
      "\n",
      "====================== result for random seed: 90 ======================\n",
      "Best Linear Regression RMSE: 56015.683029036285\n",
      "Best Ridge Regression RMSE: 59258.08686646656\n",
      "Best Lasso Regression RMSE: 59259.95062936268\n",
      "Best Decision Tree Regressor RMSE: 51586.043684427634\n",
      "Best Random Forest Regressor RMSE: 48632.30046880531\n",
      "Best Gradient Boosting Regressor RMSE: 48106.00021488515\n",
      "Best AdaBoost Regressor RMSE: 52059.94848064215\n",
      "Best XGBoost Regressor RMSE: 48034.123069097\n",
      "Best LightGBM Regressor RMSE: 48054.433150102355\n",
      "Best CatBoost Regressor RMSE: 48052.540935053934\n",
      "Best ElasticNet Regression RMSE: 59250.73275053449\n",
      "Best K-Nearest Neighbors RMSE: 50613.74596933113\n",
      "Best Support Vector Regressor RMSE: 59866.57102405065\n",
      "Best Bayesian Ridge Regression RMSE: 59260.88494990199\n",
      "Best Model: XGBoost Regressor (RMSE: 48034.123069097)\n",
      "Best Parameters for Best Model:\n",
      "{'max_depth': 4, 'n_estimators': 50}\n",
      "\n",
      "====================== result for random seed: 91 ======================\n",
      "Best Linear Regression RMSE: 56041.64702485946\n",
      "Best Ridge Regression RMSE: 59250.88151282001\n",
      "Best Lasso Regression RMSE: 59253.14432818211\n",
      "Best Decision Tree Regressor RMSE: 51610.04898590547\n",
      "Best Random Forest Regressor RMSE: 48752.463678192085\n",
      "Best Gradient Boosting Regressor RMSE: 48527.221476582854\n",
      "Best AdaBoost Regressor RMSE: 52416.253631550746\n",
      "Best XGBoost Regressor RMSE: 48446.96776893364\n",
      "Best LightGBM Regressor RMSE: 48442.112648231545\n",
      "Best CatBoost Regressor RMSE: 48507.21792671752\n",
      "Best ElasticNet Regression RMSE: 59238.57149265939\n",
      "Best K-Nearest Neighbors RMSE: 51756.66627882667\n",
      "Best Support Vector Regressor RMSE: 59894.11676283926\n",
      "Best Bayesian Ridge Regression RMSE: 59245.119394753274\n",
      "Best Model: LightGBM Regressor (RMSE: 48442.112648231545)\n",
      "Best Parameters for Best Model:\n",
      "{'max_depth': 3, 'n_estimators': 200}\n",
      "\n",
      "====================== result for random seed: 92 ======================\n",
      "Best Linear Regression RMSE: 52381.14866561466\n",
      "Best Ridge Regression RMSE: 59318.49332807554\n",
      "Best Lasso Regression RMSE: 59321.41808066524\n",
      "Best Decision Tree Regressor RMSE: 50762.44744802635\n",
      "Best Random Forest Regressor RMSE: 48960.726305530254\n",
      "Best Gradient Boosting Regressor RMSE: 48593.239528442995\n",
      "Best AdaBoost Regressor RMSE: 52564.231903206455\n",
      "Best XGBoost Regressor RMSE: 48672.06998151941\n",
      "Best LightGBM Regressor RMSE: 48512.21863975421\n",
      "Best CatBoost Regressor RMSE: 48406.10858726877\n",
      "Best ElasticNet Regression RMSE: 59286.99779778852\n",
      "Best K-Nearest Neighbors RMSE: 51196.90238270903\n",
      "Best Support Vector Regressor RMSE: 59857.92830747308\n",
      "Best Bayesian Ridge Regression RMSE: 59310.282878250844\n",
      "Best Model: CatBoost Regressor (RMSE: 48406.10858726877)\n",
      "Best Parameters for Best Model:\n",
      "{'depth': 6, 'iterations': 200}\n",
      "\n",
      "====================== result for random seed: 93 ======================\n",
      "Best Linear Regression RMSE: 54362.91473033035\n",
      "Best Ridge Regression RMSE: 58658.92522219911\n",
      "Best Lasso Regression RMSE: 58659.205403869986\n",
      "Best Decision Tree Regressor RMSE: 50878.775281848524\n",
      "Best Random Forest Regressor RMSE: 48474.20000258218\n",
      "Best Gradient Boosting Regressor RMSE: 47841.98105656847\n",
      "Best AdaBoost Regressor RMSE: 52001.31721491533\n",
      "Best XGBoost Regressor RMSE: 47695.008923028676\n",
      "Best LightGBM Regressor RMSE: 47822.714816292544\n",
      "Best CatBoost Regressor RMSE: 47789.33796449693\n",
      "Best ElasticNet Regression RMSE: 58644.33969346189\n",
      "Best K-Nearest Neighbors RMSE: 51156.70407465501\n",
      "Best Support Vector Regressor RMSE: 59169.428999422504\n",
      "Best Bayesian Ridge Regression RMSE: 58662.315947823125\n",
      "Best Model: XGBoost Regressor (RMSE: 47695.008923028676)\n",
      "Best Parameters for Best Model:\n",
      "{'max_depth': 4, 'n_estimators': 50}\n",
      "\n",
      "====================== result for random seed: 94 ======================\n",
      "Best Linear Regression RMSE: 53022.977307431414\n",
      "Best Ridge Regression RMSE: 59177.854038362646\n",
      "Best Lasso Regression RMSE: 59183.02464385754\n",
      "Best Decision Tree Regressor RMSE: 52067.99291257243\n",
      "Best Random Forest Regressor RMSE: 48984.487564280855\n",
      "Best Gradient Boosting Regressor RMSE: 48370.7344989496\n",
      "Best AdaBoost Regressor RMSE: 52291.59570907391\n",
      "Best XGBoost Regressor RMSE: 48299.542909970056\n",
      "Best LightGBM Regressor RMSE: 48094.386196735126\n",
      "Best CatBoost Regressor RMSE: 48278.93055433422\n",
      "Best ElasticNet Regression RMSE: 59144.03687882585\n",
      "Best K-Nearest Neighbors RMSE: 51708.54102803589\n",
      "Best Support Vector Regressor RMSE: 59636.67517492197\n",
      "Best Bayesian Ridge Regression RMSE: 59157.92313347613\n",
      "Best Model: LightGBM Regressor (RMSE: 48094.386196735126)\n",
      "Best Parameters for Best Model:\n",
      "{'max_depth': 4, 'n_estimators': 100}\n",
      "\n",
      "====================== result for random seed: 95 ======================\n",
      "Best Linear Regression RMSE: 53436.5099585931\n",
      "Best Ridge Regression RMSE: 58703.03984464084\n",
      "Best Lasso Regression RMSE: 58704.90911274524\n",
      "Best Decision Tree Regressor RMSE: 52732.20316864405\n",
      "Best Random Forest Regressor RMSE: 49539.48809512589\n",
      "Best Gradient Boosting Regressor RMSE: 48702.32230265211\n",
      "Best AdaBoost Regressor RMSE: 52020.805502647105\n",
      "Best XGBoost Regressor RMSE: 48820.67997398532\n",
      "Best LightGBM Regressor RMSE: 48245.69400688989\n",
      "Best CatBoost Regressor RMSE: 48523.918898620504\n",
      "Best ElasticNet Regression RMSE: 58695.830662976885\n",
      "Best K-Nearest Neighbors RMSE: 51991.35038312913\n",
      "Best Support Vector Regressor RMSE: 59252.75990004208\n",
      "Best Bayesian Ridge Regression RMSE: 58705.088274403686\n",
      "Best Model: LightGBM Regressor (RMSE: 48245.69400688989)\n",
      "Best Parameters for Best Model:\n",
      "{'max_depth': 4, 'n_estimators': 100}\n",
      "\n",
      "====================== result for random seed: 96 ======================\n",
      "Best Linear Regression RMSE: 53854.95729959621\n",
      "Best Ridge Regression RMSE: 58808.58530056951\n",
      "Best Lasso Regression RMSE: 58810.64874239028\n",
      "Best Decision Tree Regressor RMSE: 52426.79933006315\n",
      "Best Random Forest Regressor RMSE: 49117.81379320035\n",
      "Best Gradient Boosting Regressor RMSE: 48428.655666249135\n",
      "Best AdaBoost Regressor RMSE: 52307.53994604805\n",
      "Best XGBoost Regressor RMSE: 48407.38634217784\n",
      "Best LightGBM Regressor RMSE: 48223.49433032355\n",
      "Best CatBoost Regressor RMSE: 48401.38231212013\n",
      "Best ElasticNet Regression RMSE: 58801.25663920916\n",
      "Best K-Nearest Neighbors RMSE: 51337.93661773762\n",
      "Best Support Vector Regressor RMSE: 59513.37911634635\n",
      "Best Bayesian Ridge Regression RMSE: 58811.86558152188\n",
      "Best Model: LightGBM Regressor (RMSE: 48223.49433032355)\n",
      "Best Parameters for Best Model:\n",
      "{'max_depth': 4, 'n_estimators': 100}\n",
      "\n",
      "====================== result for random seed: 97 ======================\n",
      "Best Linear Regression RMSE: 56217.08555060967\n",
      "Best Ridge Regression RMSE: 59139.28901781386\n",
      "Best Lasso Regression RMSE: 59141.37575428654\n",
      "Best Decision Tree Regressor RMSE: 52191.268189184084\n",
      "Best Random Forest Regressor RMSE: 49019.056087989666\n",
      "Best Gradient Boosting Regressor RMSE: 48510.55107179334\n",
      "Best AdaBoost Regressor RMSE: 52494.308947877784\n",
      "Best XGBoost Regressor RMSE: 48508.740417384804\n",
      "Best LightGBM Regressor RMSE: 48322.61364152763\n",
      "Best CatBoost Regressor RMSE: 48573.23863615365\n",
      "Best ElasticNet Regression RMSE: 59127.644058714766\n",
      "Best K-Nearest Neighbors RMSE: 51701.74639661608\n",
      "Best Support Vector Regressor RMSE: 59719.161395581636\n",
      "Best Bayesian Ridge Regression RMSE: 59144.112699810416\n",
      "Best Model: LightGBM Regressor (RMSE: 48322.61364152763)\n",
      "Best Parameters for Best Model:\n",
      "{'max_depth': 4, 'n_estimators': 200}\n",
      "\n",
      "====================== result for random seed: 98 ======================\n",
      "Best Linear Regression RMSE: 57821.28493253926\n",
      "Best Ridge Regression RMSE: 59897.688402705266\n",
      "Best Lasso Regression RMSE: 59901.36252457099\n",
      "Best Decision Tree Regressor RMSE: 53060.645529274785\n",
      "Best Random Forest Regressor RMSE: 49372.91977941757\n",
      "Best Gradient Boosting Regressor RMSE: 48880.667054410456\n",
      "Best AdaBoost Regressor RMSE: 52671.20732861188\n",
      "Best XGBoost Regressor RMSE: 48835.02140482683\n",
      "Best LightGBM Regressor RMSE: 48414.97976278085\n",
      "Best CatBoost Regressor RMSE: 48746.415785895195\n",
      "Best ElasticNet Regression RMSE: 59873.264549951215\n",
      "Best K-Nearest Neighbors RMSE: 51575.207040036534\n",
      "Best Support Vector Regressor RMSE: 60456.58642217582\n",
      "Best Bayesian Ridge Regression RMSE: 59881.90674070638\n",
      "Best Model: LightGBM Regressor (RMSE: 48414.97976278085)\n",
      "Best Parameters for Best Model:\n",
      "{'max_depth': 4, 'n_estimators': 200}\n",
      "\n",
      "====================== result for random seed: 99 ======================\n",
      "Best Linear Regression RMSE: 53730.75691842955\n",
      "Best Ridge Regression RMSE: 58864.37772574979\n",
      "Best Lasso Regression RMSE: 58866.61445939062\n",
      "Best Decision Tree Regressor RMSE: 51454.32998698094\n",
      "Best Random Forest Regressor RMSE: 49176.04053860878\n",
      "Best Gradient Boosting Regressor RMSE: 48126.82875933173\n",
      "Best AdaBoost Regressor RMSE: 52114.47484341753\n",
      "Best XGBoost Regressor RMSE: 48026.61780380564\n",
      "Best LightGBM Regressor RMSE: 48054.159125111175\n",
      "Best CatBoost Regressor RMSE: 48188.01624659341\n",
      "Best ElasticNet Regression RMSE: 58852.74860706561\n",
      "Best K-Nearest Neighbors RMSE: 51128.81016433822\n",
      "Best Support Vector Regressor RMSE: 59476.95358593344\n",
      "Best Bayesian Ridge Regression RMSE: 58863.02891764761\n",
      "Best Model: XGBoost Regressor (RMSE: 48026.61780380564)\n",
      "Best Parameters for Best Model:\n",
      "{'max_depth': 4, 'n_estimators': 50}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import (\n",
    "    RandomForestRegressor,\n",
    "    GradientBoostingRegressor,\n",
    "    AdaBoostRegressor,\n",
    ")\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "import catboost as catb\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "import random\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "import logging\n",
    "import datetime  # Import the datetime module\n",
    "\n",
    "# Generate a timestamp\n",
    "timestamp = datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "\n",
    "# Configure logging with the timestamp in the log filename\n",
    "log_filename = f'logs/model_selection_{timestamp}.log'  # Include the timestamp in the filename\n",
    "\n",
    "logging.basicConfig(filename=log_filename, level=logging.INFO, format='%(asctime)s - %(levelname)s: %(message)s')\n",
    "\n",
    "# Function to log messages to both the console and the log file\n",
    "def log_message(message):\n",
    "    print(message)  # Print to console\n",
    "    logging.info(message)  # Log to file\n",
    "\n",
    "# The rest of your code remains the same...\n",
    "\n",
    "\n",
    "# Split the data into training, validation, and test sets\n",
    "for seed_number in range(100):\n",
    "    log_message(f\"\\n====================== result for random seed: {seed_number} ======================\")\n",
    "    X_train, X_val, y_train, y_val = train_test_split(train_data.drop(columns=[\"y\",\"UID\",\"col_4\"]), train_data[\"y\"], test_size=0.1, random_state=seed_number)\n",
    "\n",
    "    # Define a list of regression models to compare\n",
    "    models = {\n",
    "        'Linear Regression': LinearRegression(),\n",
    "        'Ridge Regression': Ridge(),\n",
    "        'Lasso Regression': Lasso(),\n",
    "        'Decision Tree Regressor': DecisionTreeRegressor(),\n",
    "        'Random Forest Regressor': RandomForestRegressor(),\n",
    "        'Gradient Boosting Regressor': GradientBoostingRegressor(),\n",
    "        'AdaBoost Regressor': AdaBoostRegressor(),\n",
    "        'XGBoost Regressor': xgb.XGBRegressor(),\n",
    "        'LightGBM Regressor': lgb.LGBMRegressor(verbose=-1),\n",
    "        'CatBoost Regressor': catb.CatBoostRegressor(silent=True),\n",
    "        'ElasticNet Regression': ElasticNet(),\n",
    "        'K-Nearest Neighbors': KNeighborsRegressor(),\n",
    "        'Support Vector Regressor': SVR(),\n",
    "        'Bayesian Ridge Regression': BayesianRidge(),\n",
    "    }\n",
    "\n",
    "    # Define hyperparameter grids for each model, including previous models\n",
    "    param_grids = {\n",
    "        'Linear Regression': {},\n",
    "        'Ridge Regression': {'alpha': [0.1, 1.0, 10.0]},\n",
    "        'Lasso Regression': {'alpha': [0.1, 1.0, 10.0]},\n",
    "        'Decision Tree Regressor': {'max_depth': [None, 10, 20, 30]},\n",
    "        'Random Forest Regressor': {'n_estimators': [50, 100, 200], 'max_depth': [None, 10, 20, 30]},\n",
    "        'Gradient Boosting Regressor': {'n_estimators': [50, 100, 200], 'max_depth': [3, 4, 5]},\n",
    "        'AdaBoost Regressor': {'n_estimators': [50, 100, 200], 'learning_rate': [0.01, 0.1, 1.0]},\n",
    "        'XGBoost Regressor': {'n_estimators': [50, 100, 200], 'max_depth': [3, 4, 5]},\n",
    "        'LightGBM Regressor': {'n_estimators': [50, 100, 200], 'max_depth': [3, 4, 5]},\n",
    "        'CatBoost Regressor': {'iterations': [50, 100, 200], 'depth': [4, 6, 8]},\n",
    "        'ElasticNet Regression': {'alpha': [0.1, 1.0, 10.0], 'l1_ratio': [0.25, 0.5, 0.75]},\n",
    "        'K-Nearest Neighbors': {'n_neighbors': [3, 5, 7, 10], 'weights': ['uniform', 'distance']},\n",
    "        'Support Vector Regressor': {'C': [0.1, 1.0, 10.0], 'kernel': ['linear', 'rbf']},\n",
    "        'Bayesian Ridge Regression': {'max_iter': [100, 300, 500], 'alpha_1': [1e-6, 1e-7], 'alpha_2': [1e-6, 1e-7]},\n",
    "    }\n",
    "\n",
    "\n",
    "    # Initialize variables to store best models, their RMSE scores, and best parameters\n",
    "    best_models = {}\n",
    "    best_rmse_scores = {}\n",
    "    best_parameters = {}\n",
    "\n",
    "    # Hyperparameter tuning loop with k-fold cross-validation (k=10)\n",
    "    for model_name, model in models.items():\n",
    "        param_grid = param_grids[model_name]\n",
    "        \n",
    "        best_model = None  # Initialize best_model\n",
    "        best_param = None  # Initialize best_param\n",
    "        \n",
    "        if param_grid:\n",
    "            search = GridSearchCV(model, param_grid, scoring='neg_mean_squared_error', cv=10)  # Change cv to 10\n",
    "            search.fit(X_train, y_train)\n",
    "            \n",
    "            best_model = search.best_estimator_\n",
    "            best_rmse = np.sqrt(-search.best_score_)\n",
    "            best_param = search.best_params_\n",
    "        else:\n",
    "            # Perform k-fold cross-validation with k=10\n",
    "            scores = cross_val_score(model, X_train, y_train, scoring='neg_mean_squared_error', cv=10)  # Change cv to 10\n",
    "            \n",
    "            # Find the best RMSE score and corresponding model\n",
    "            best_rmse = np.sqrt(-scores.max())\n",
    "        \n",
    "        best_models[model_name] = best_model\n",
    "        best_rmse_scores[model_name] = best_rmse\n",
    "        best_parameters[model_name] = best_param\n",
    "        log_message(f\"Best {model_name} RMSE: {best_rmse}\")\n",
    "\n",
    "    # Find the model with the lowest RMSE\n",
    "    best_model_name = min(best_rmse_scores, key=best_rmse_scores.get)\n",
    "    log_message(f\"Best Model: {best_model_name} (RMSE: {best_rmse_scores[best_model_name]})\")\n",
    "\n",
    "    # Print the best parameters for the best model\n",
    "    log_message(\"Best Parameters for Best Model:\")\n",
    "    log_message(best_parameters[best_model_name])\n",
    "\n",
    "    # # Evaluate the best model on the test data\n",
    "    # best_model = best_models[best_model_name]\n",
    "    # y_test_pred = best_model.predict(X_test)\n",
    "    # test_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
    "    # print(f\"Test RMSE of Best Model: {test_rmse}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
